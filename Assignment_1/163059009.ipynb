{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "from numpy.linalg import inv;\n",
    "from numpy.linalg import det;\n",
    "import math;\n",
    "\n",
    "# Will read the file and convert it into two dataset one train data other validate data\n",
    "def readTrainData(fileName):\n",
    "    row_index=0;\n",
    "    phi=list();\n",
    "    y=list();\n",
    "    with open(fileName) as f:\n",
    "        for line in f:\n",
    "            if row_index >0:\n",
    "                phi_i=list((float(n) for n in line.split('\\n')[0].split(\",\") ));\n",
    "                if(addW0Col):\n",
    "                    phi_i[0]=1;\n",
    "                else:# removing id col.\n",
    "                    phi_i.pop();\n",
    "                # last row is value of yi                \n",
    "                y_i=phi_i.pop(len(phi_i)-1); \n",
    "                phi.append(phi_i);             \n",
    "                y.append(y_i);\n",
    "            row_index+=1;\n",
    "    return [phi,y];\n",
    "#End-readTrainData\n",
    "\n",
    "# Will read the file and convert it into dataset for Testing the Model\n",
    "def readTestData(fileName):\n",
    "    row_index=0;\n",
    "    phi=list();\n",
    "    y=list();\n",
    "    with open(fileName) as f:\n",
    "        for line in f:\n",
    "            if row_index >0:                \n",
    "                phi_i=list((float(n) for n in line.split('\\n')[0].split(\",\") ));\n",
    "                if(addW0Col):\n",
    "                    phi_i[0]=1;\n",
    "                else:# removing id col.\n",
    "                    phi_i.pop();                \n",
    "                phi.append(phi_i);                             \n",
    "            row_index+=1;\n",
    "    m=len(phi);    \n",
    "    return phi;\n",
    "#End-readTrainData\n",
    "\n",
    "\n",
    "\n",
    "#write-output\n",
    "def writeTestData(ystar):\n",
    "    fo = open(\"output.csv\", \"w\");    \n",
    "    fo.write(\"ID,MEDV\\n\");\n",
    "    m=len(ystar);\n",
    "    for i in range(m):\n",
    "        fo.write(str(i)+\",\"+str(ystar[i])+\"\\n\");\n",
    "    fo.close();\n",
    "    pass;\n",
    "\n",
    "# Return det of matrix\n",
    "def getDet(A):\n",
    "    d=det(A);\n",
    "    if(d<10**-10):\n",
    "        return 0;\n",
    "    return d;\n",
    "\n",
    "\n",
    "#Return RMS: root mean square error\n",
    "def getRMS(y,yStar):\n",
    "    m=len(y);\n",
    "    sigma=0;\n",
    "    for i in range(m):\n",
    "        delta=(y[i]-yStar[i]);\n",
    "        delta=delta*delta;\n",
    "        sigma=sigma+delta;\n",
    "    meanSq=sigma/m;   \n",
    "    rms=math.sqrt(meanSq);\n",
    "    return rms;\n",
    "    pass;\n",
    "\n",
    "#For ploting graph of RMS VS Iteration\n",
    "def plotGraph(x,y):\n",
    "    import matplotlib.pyplot as plt;\n",
    "    plt.plot(x,y)\n",
    "    plt.ylabel('rms')\n",
    "    plt.xlabel('iteration');\n",
    "    plt.show();\n",
    "    pass;\n",
    "\n",
    "#Record readings for gradient descent\n",
    "def writeReadingInFile(filename,alpha,lam,iteration,rms,p):\n",
    "    import os.path;\n",
    "    import datetime;\n",
    "    import time;\n",
    "    ts = datetime.datetime.fromtimestamp(time.time()).strftime('%d-%m-%Y %H:%M:%S')\n",
    "    if(os.path.exists(filename)==False):\n",
    "        fo = open(filename, \"w\"); \n",
    "        fo.write(\"iteration,norm,alpha,lam,rms,timestamp\\n\");\n",
    "        fo.write(str(iteration)+\",\"+str(p)+\",\"+str(alpha)+\",\"+str(lam)+\",\"+str(rms)+\",\"+str(ts)+\"\\n\");\n",
    "    else:\n",
    "        fo = open(filename, \"a\"); \n",
    "        fo.write(str(iteration)+\",\"+str(p)+\",\"+str(alpha)+\",\"+str(lam)+\",\"+str(rms)+\",\"+str(ts)+\"\\n\");\n",
    "    fo.close();                    \n",
    "    pass;\n",
    "\n",
    "\n",
    "#normalize the data set ny (x-u)/s where s is max-min\n",
    "def normalizePhi(unNormalizedPhi):    \n",
    "    phi=np.array(unNormalizedPhi);\n",
    "    print(\"Normalizing Phi...\");  \n",
    "    std=phi.std(0);\n",
    "    mean=phi.mean(0); \n",
    "    if(addW0Col):#making first col. mean as 0              \n",
    "        std[0]=1;\n",
    "        mean[0]=0;\n",
    "    phi_normalize=(phi-mean)/std;    \n",
    "    print(\"Normalization done.\");\n",
    "    return phi_normalize;\n",
    "    pass;\n",
    "\n",
    "#pridict of y* given w* QW=y*\n",
    "def pridict(dataset,weight):\n",
    "    phi=np.array(dataset);\n",
    "    w=np.array(weight);\n",
    "    ystar=np.dot(phi,w);\n",
    "    return ystar;\n",
    "    pass;\n",
    "\n",
    "# Finding w*=(QTQ)^-1QTY\n",
    "def trainUsingClosedFormEquation(dataset,output):\n",
    "    m=len(dataset);\n",
    "    n=len(dataset[0]);\n",
    "    print(\"------------------\");\n",
    "    #print(dataset);\n",
    "    phi=np.array(dataset);\n",
    "    print(\"------------------\");\n",
    "    #print(phi);    \n",
    "    y=np.array(output);\n",
    "    phiT=np.transpose(phi);\n",
    "    #(QTQ)    \n",
    "    phiT_phi=np.dot(phiT,phi);   \n",
    "    d=getDet(phiT_phi)\n",
    "    if(d>0):\n",
    "        #(QTQ)^-1\n",
    "        phiT_phi_inv=inv(phiT_phi);\n",
    "        #(QTQ)^-1QT\n",
    "        phiT_phi_inv_phiT=np.dot(phiT_phi_inv,phiT);  \n",
    "        #(QTQ)^-1QT*Y\n",
    "        w=np.dot(phiT_phi_inv_phiT,y);\n",
    "        return w;\n",
    "    else:\n",
    "        print(\"Error:Phi is NOT full column rank.\");\n",
    "        return None;\n",
    "    pass;\n",
    "\n",
    "\n",
    "\n",
    "def numpiTestFun():\n",
    "    A2= np.matrix([[4,6],[2,8]])        \n",
    "    A3= np.matrix([[1,2,3],[4,5,7],[7,8,9]])\n",
    "    A=A2;\n",
    "    print(A);\n",
    "    print(np.power(A,0.5));\n",
    "    print(A);\n",
    "    print(\"Det(A):\"+str(getDet(A)));\n",
    "    B= np.transpose(A);\n",
    "    C=inv(A);\n",
    "    #print(C);\n",
    "    print(np.dot(A,C));\n",
    "    print(A.std(0));\n",
    "    print(A.mean(0));\n",
    "    print(normalizePhi(A));\n",
    "    norm=(A-A.mean(0))/A.std(0);    \n",
    "    print(norm);    \n",
    "    print();\n",
    "    pass;\n",
    "\n",
    "\n",
    "# Finding w*=(QTQ+lamI)^-1QTY\n",
    "def trainUsingClosedFormRidgeEq(dataset,output):\n",
    "    #-------------------------------------\n",
    "    # Best value: m=300 validate=120\n",
    "    # addW0=True: c=0.376654. Not lamd\n",
    "    #-------------------------------------\n",
    "    m=len(dataset);\n",
    "    n=len(dataset[0]);    \n",
    "    phi=np.array(dataset);\n",
    "    y=np.array(output);\n",
    "    phiT=np.transpose(phi);    \n",
    "    #(QTQ)    \n",
    "    phiT_phi=np.dot(phiT,phi);\n",
    "    n=len(phiT_phi);\n",
    "    lam=0.5;\n",
    "    c=.376654;\n",
    "    I=np.identity(n);\n",
    "    lamI=lam*I;\n",
    "    d=getDet(phiT_phi)\n",
    "    #--------------------------------------\n",
    "    if(d>0):\n",
    "        #(QTQ+lamI)^-1\n",
    "        phiT_phi_inv=inv((phiT_phi+c));\n",
    "        #(QTQ+lamI)^-1QT\n",
    "        phiT_phi_inv_phiT=np.dot(phiT_phi_inv,phiT);  \n",
    "        #(QTQ+lamI)^-1QT*Y\n",
    "        w=np.dot(phiT_phi_inv_phiT,y);\n",
    "        return w;\n",
    "    else:\n",
    "        print(\"Error:Phi is NOT full column rank.\");\n",
    "        return None;\n",
    "    pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GD: Least Sq. Without Regularlization\n",
    "def gardientDescentErrorFun(phi,y):\n",
    "    m=len(y);#no of data points\n",
    "    n=len(phi[0]);# no. of features    \n",
    "    alpha=0.22;# learning parameter\n",
    "    maxIteration=10000;\n",
    "    phi=np.array(phi);\n",
    "    y=(np.array(y));#converting row vector to col vector    \n",
    "    wk0=np.zeros(n);# Nx1 vector\n",
    "    phiT=np.transpose(phi);\n",
    "    phiTphi=np.dot(phiT,phi);   \n",
    "    phiTy=np.dot(phiT,y);   \n",
    "    alphaBym=alpha/m;\n",
    "    xaxis=list();\n",
    "    yaxis=list();\n",
    "    #----------------------\n",
    "    print(\"Training Started (Least Sq. Without Regularlization) ...\");\n",
    "    for i in range(maxIteration):  \n",
    "        wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)));                \n",
    "        ystar=pridict(phi,wk1);\n",
    "        rms=getRMS(y,ystar);    \n",
    "        xaxis.append(i);\n",
    "        yaxis.append(rms);\n",
    "        percentComplete=((i+1)*100)/maxIteration;\n",
    "        if( percentComplete%10==0 ):\n",
    "            print(\"Percent Completed\",percentComplete);\n",
    "        wk0=wk1;\n",
    "    print(\"Final Trained RMS:\",rms);\n",
    "    plotGraph(xaxis,yaxis);\n",
    "    return wk1;\n",
    "    pass;\n",
    "\n",
    "# GD: Least Sq. With ||w||_(1.5)^(1.5)\n",
    "def gardientDescentWithPnom(phi,y,p):\n",
    "    m=len(y);#no of data points\n",
    "    n=len(phi[0]);# no. of features    \n",
    "    alpha=0.2 #learning parameter\n",
    "    maxIteration=100000;\n",
    "    phi=np.array(phi);\n",
    "    y=(np.array(y));#converting row vector to col vector    \n",
    "    wk0=np.zeros(n);# Nx1 vector    \n",
    "    wk0=phi[1];\n",
    "    phiT=np.transpose(phi);\n",
    "    phiTphi=np.dot(phiT,phi);   \n",
    "    phiTy=np.dot(phiT,y);   \n",
    "    alphaBym=alpha/m;\n",
    "    lam=0.31;\n",
    "    xaxis=list();\n",
    "    yaxis=list();\n",
    "    algFixedIteration=False;\n",
    "    logReading=True;\n",
    "    diff=0;\n",
    "    wPow=p-1;\n",
    "    if (p<=1):\n",
    "        print(\"Error: norm p is less than 1 i.p p=\",wPow);\n",
    "        return None;\n",
    "        \n",
    "    #-----------------------------------------------------------------\n",
    "    print(\"Training Started (Least Sq. With Ridge) ...\");\n",
    "    if (algFixedIteration):\n",
    "        for iteration in range(0,maxIteration):\n",
    "            if (wPow>1):\n",
    "                wk0Pow=np.power(wk0,wPow);            \n",
    "            else:\n",
    "                wk0Pow=wk0;\n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0Pow))); \n",
    "            \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            percentComplete=((iteration+1)*100)/maxIteration;\n",
    "            if( percentComplete%10==0 ):\n",
    "                print(\"Percent Completed\",percentComplete);\n",
    "            wk0=wk1;\n",
    "    else:\n",
    "        diffOffset=1e-20;\n",
    "        iteration=0;\n",
    "        oldRms=0;\n",
    "        voldRms=0;\n",
    "        while (True):            \n",
    "            if (wPow>1):\n",
    "                wk0Pow=np.power(wk0,wPow);            \n",
    "            else:\n",
    "                wk0Pow=wk0;\n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0Pow)));  \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            diff=abs(oldRms-rms);\n",
    "            \n",
    "            vystar=pridict(validateDatasetPhi,wk1);\n",
    "            vrms=getRMS(validateDatasetY,vystar);\n",
    "            vdiff=voldRms-vrms;\n",
    "            \n",
    "            if(iteration>0 and  diff<=diffOffset):\n",
    "                break;\n",
    "            if(False and iteration%100==0 ):\n",
    "                print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff,\" vrms:\",vrms,\" vdiff:\", vdiff);            \n",
    "            wk0=wk1;\n",
    "            oldRms=rms;\n",
    "            voldRms=vrms;\n",
    "            iteration+=1;\n",
    "        print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff,\" vrms:\",vrms,\" vdiff:\", vdiff);    \n",
    "\n",
    "    print(\"Final Trained RMS:\",rms ,\". Iteration needed \", iteration);       \n",
    "    #-------------------------------------------------------------\n",
    "    if(logReading):\n",
    "        writeReadingInFile(\"pnom.csv\",alpha,lam,iteration,rms,p);\n",
    "    plotGraph(xaxis,yaxis);\n",
    "    return wk1; \n",
    "\n",
    "#wStart=gardientDescentWithRidge(trainDatasetPhi,trainDatasetY);\n",
    "#wStart=gardientDescentWithPnom(trainDatasetPhi,trainDatasetY,4);\n",
    "#mainRidgeClosedFormSol();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Trained Dataset from file...\n",
      "Normalizing Phi...\n",
      "Normalization done.\n",
      "Normalizing Phi...\n",
      "Normalization done.\n",
      "Fetching of data Completed.\n",
      "Train Size:300\n",
      "Validate Size:120\n",
      "Training Started (Least Sq. With Ridge) ...\n",
      "Percent Completed 10.0 rms: 4.058886855464154\n",
      "Percent Completed 20.0 rms: 3.9613314063836293\n",
      "Percent Completed 30.0 rms: 3.9453286752248657\n",
      "Percent Completed 40.0 rms: 3.9420473286970528\n",
      "Percent Completed 50.0 rms: 3.9412061910866654\n",
      "Percent Completed 60.0 rms: 3.9409447595290374\n",
      "Percent Completed 70.0 rms: 3.9408529341384337\n",
      "Percent Completed 80.0 rms: 3.9408186232202644\n",
      "Percent Completed 90.0 rms: 3.9408054412713946\n",
      "Percent Completed 100.0 rms: 3.9408003156320706\n",
      "Final Trained RMS: 3.9408003156320706 . Iteration needed  999999\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAF5CAYAAACBThBWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b968f16a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Desent ||Norm||=2 RMS: 4.449621281343252\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mainClosedFormSol(dataset):\n",
    "    \n",
    "    tdsPhi=dataset[0];\n",
    "    tdsY=dataset[1];\n",
    "    vdsPhi=dataset[2];\n",
    "    vdsY=dataset[3];\n",
    "    ttds=dataset[4];\n",
    "    #--------------------[Closed Form Sol without Regularlization]--------------------------------\n",
    "    #Find w*\n",
    "    wStar=trainUsingClosedFormEquation(tdsPhi,tdsY);\n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(vdsPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(vdsY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(ttds,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Closed Form Solution RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    pass;\n",
    "\n",
    "\n",
    "def mainRidgeClosedFormSol(dataset):\n",
    "    #-------------------------------------\n",
    "    # Best value: m=300 validate=120\n",
    "    #-------------------------------------    \n",
    "    tdsPhi=dataset[0];\n",
    "    tdsY=dataset[1];\n",
    "    vdsPhi=dataset[2];\n",
    "    vdsY=dataset[3];\n",
    "    ttds=dataset[4];\n",
    "    #--------------------[Closed Form Sol without Regularlization]--------------------------------\n",
    "    #Find w*\n",
    "    wStar=trainUsingClosedFormRidgeEq(tdsPhi,tdsY);\n",
    "    print(wStar);\n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(vdsPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(vdsY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(ttds,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Closed FormSol With Ridge RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    pass;\n",
    "\n",
    "def mainGradientDesent(dataset):\n",
    "    tdsPhi=dataset[0];\n",
    "    tdsY=dataset[1];\n",
    "    vdsPhi=dataset[2];\n",
    "    vdsY=dataset[3];\n",
    "    ttds=dataset[4];\n",
    "    #--------------------[Gradient decent without Regularlization]--------------------------------\n",
    "    wStar=gardientDescentWithRidge(tdsPhi,tdsY);\n",
    "    #wStar=gardientDescentWithPnom(trainDatasetPhi,trainDatasetY,(4/3));\n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(vdsPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(vdsY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(ttds,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Gradient Desent ||Norm||=2 RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "#split train data into Train and Validate\n",
    "def spitTrainDataset(phi,y):\n",
    "    m=len(phi);        \n",
    "    tdsSize=int(m*trainDSSizePercentage);\n",
    "    l=300;\n",
    "    trainDatasetPhi=phi[0:l];\n",
    "    trainDatasetY=y[0:l];\n",
    "    validateDatasetPhi=phi[tdsSize:m];\n",
    "    validateDatasetY=y[tdsSize:m];    \n",
    "   \n",
    "    return [trainDatasetPhi,trainDatasetY,validateDatasetPhi,validateDatasetY];    \n",
    "    pass\n",
    "\n",
    "def createNewFeatureMatrix(phi,maxDeg=4):    \n",
    "    newPhi=np.array(phi);\n",
    "    p=np.array(phi);        \n",
    "    if(addW0Col):#deleting first W0Col coffecient is 1\n",
    "        p=np.delete(p,0,1);    \n",
    "    i=2;\n",
    "    while(i<=maxDeg):\n",
    "        pPowI=np.power(p,i);        \n",
    "        newPhi=np.concatenate((newPhi,pPowI),axis=1);\n",
    "        i+=1;\n",
    "    return newPhi;\n",
    "    pass;\n",
    "\n",
    "# GD: Least Sq. With Ridges\n",
    "def gardientDescentWithRidge(phi,y,wi=-1):\n",
    "    m=len(y);#no of data points\n",
    "    n=len(phi[0]);# no. of features    \n",
    "    alpha=0.0003;# learning parameter\n",
    "    maxIteration=1000000;\n",
    "    phi=np.array(phi);\n",
    "    y=(np.array(y));#converting row vector to col vector    \n",
    "    if(wi==-1):\n",
    "        wk0=np.zeros(n);# Nx1 vector\n",
    "    else:\n",
    "        wk0=phi[wi]\n",
    "    \n",
    "    phiT=np.transpose(phi);\n",
    "    phiTphi=np.dot(phiT,phi);   \n",
    "    phiTy=np.dot(phiT,y);   \n",
    "    alphaBym=alpha/m;\n",
    "    lam=0.301;    \n",
    "    xaxis=list();\n",
    "    yaxis=list();\n",
    "    algFixedIteration=True;\n",
    "    logReading=True;\n",
    "    diff=0;\n",
    "    #-----------------------------------------------------------------\n",
    "    #Best Tested Constant\n",
    "    #1)With 13 features i.e original Phi\n",
    "    #normalize phi: true.\n",
    "    #aplha=.212 lamda=.301 tds=300 vds=120 Iteo/p=4.8310 rms\n",
    "    #Note: Tried for different initial wk0 from phi matrix but o/p remain same\n",
    "    #\n",
    "    #2)With 26 features i.e newphi=phi + phi^2\n",
    "    #normalize phi: true; algFixedIteration=True; maxIteration=1000000;\n",
    "    #aplha=.0003 lamda=.301 tds=300 vds=120 o/p=3.940800315632070 rms\n",
    "    #Tried for different initial wk0 but o/p remain same\n",
    "    #-----------------------------------------------------------------\n",
    "    print(\"Training Started (Least Sq. With Ridge) ...\");\n",
    "    if (algFixedIteration):\n",
    "        for iteration in range(0,maxIteration):  \n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0)));              \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            percentComplete=((iteration+1)*100)/maxIteration;\n",
    "            if( percentComplete%10==0 ):\n",
    "                print(\"Percent Completed\",percentComplete,\"rms:\",rms);                \n",
    "            wk0=wk1;\n",
    "    else:\n",
    "        diffOffset=1e-20;\n",
    "        iteration=0;\n",
    "        oldRms=0;\n",
    "        voldRms=0;\n",
    "        while (True):\n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0)));                     \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            diff=abs(oldRms-rms);            \n",
    "            if(iteration>0 and diff<diffOffset):\n",
    "                break;\n",
    "            if(iteration%100==0 ):\n",
    "                print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff);            \n",
    "            wk0=wk1;\n",
    "            oldRms=rms;\n",
    "            iteration+=1;\n",
    "        print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff);    \n",
    "           \n",
    "    print(\"Final Trained RMS:\",rms ,\". Iteration needed \", iteration);    \n",
    "    #-------------------------------------------------------------\n",
    "    if(logReading):\n",
    "        writeReadingInFile(\"ridge1.csv\",alpha,lam,iteration,rms,2);\n",
    "    plotGraph(xaxis,yaxis);\n",
    "    return wk1;\n",
    "\n",
    "\n",
    "\n",
    "#--settings--\n",
    "np.set_printoptions(suppress=True)\n",
    "#---init---\n",
    "dir=\"\"\n",
    "trainFile=dir+\"train.csv\";\n",
    "testFile=dir+\"test.csv\";\n",
    "trainDSSizePercentage=0.7; # x*100 percentage. 1-x data set will be used for validating\n",
    "addW0Col=True;\n",
    "#---------------------------------------------\n",
    "print(\"Fetching Trained Dataset from file...\");\n",
    "dataset=readTrainData(trainFile);\n",
    "testDS=readTestData(testFile);\n",
    "phiSet=dataset[0];\n",
    "ySet=dataset[1];\n",
    "phiSet_norm=normalizePhi(phiSet);\n",
    "testDS_norm=normalizePhi(testDS);\n",
    "tds=spitTrainDataset(phiSet,ySet);\n",
    "tds_norm=spitTrainDataset(phiSet_norm,ySet);\n",
    "\n",
    "print(\"Fetching of data Completed.\");\n",
    "\n",
    "#train set\n",
    "trainDatasetPhi=tds[0];\n",
    "trainDatasetY=tds[1];\n",
    "validateDatasetPhi=tds[2];\n",
    "validateDatasetY=tds[3];\n",
    "\n",
    "trainDatasetPhi_norm=tds_norm[0];\n",
    "trainDatasetY_norm=tds_norm[1];\n",
    "validateDatasetPhi_norm=tds_norm[2];\n",
    "validateDatasetY_norm=tds_norm[3];\n",
    "\n",
    "deg=2;\n",
    "trainDatasetPhi_norm=createNewFeatureMatrix(trainDatasetPhi_norm,deg);\n",
    "validateDatasetPhi_norm=createNewFeatureMatrix(validateDatasetPhi_norm,deg);\n",
    "testDS_norm=createNewFeatureMatrix(testDS_norm,deg);\n",
    "\n",
    "print(\"Train Size:\"+str(len(trainDatasetPhi)));\n",
    "print(\"Validate Size:\"+str(len(validateDatasetPhi)));\n",
    "\n",
    "ds=[trainDatasetPhi,trainDatasetY,validateDatasetPhi,validateDatasetY,testDS];\n",
    "ds_norm=[trainDatasetPhi_norm,trainDatasetY,validateDatasetPhi_norm,validateDatasetY,testDS_norm];\n",
    "#mainClosedFormSol(ds);\n",
    "#mainRidgeClosedFormSol(ds_norm);\n",
    "mainGradientDesent(ds_norm);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
