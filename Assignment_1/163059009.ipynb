{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "from numpy.linalg import inv;\n",
    "from numpy.linalg import det;\n",
    "import math;\n",
    "\n",
    "# Will read the file and convert it into two dataset one train data other validate data\n",
    "def readTrainData(fileName):\n",
    "    row_index=0;\n",
    "    phi=list();\n",
    "    y=list();\n",
    "    with open(fileName) as f:\n",
    "        for line in f:\n",
    "            if row_index >0:\n",
    "                phi_i=list((float(n) for n in line.split('\\n')[0].split(\",\") ));\n",
    "                phi_i[0]=1;            \n",
    "                # last row is value of yi                \n",
    "                y_i=phi_i.pop(len(phi_i)-1); \n",
    "                phi.append(phi_i);             \n",
    "                y.append(y_i);\n",
    "            row_index+=1;\n",
    "    return [phi,y];\n",
    "#End-readTrainData\n",
    "\n",
    "# Will read the file and convert it into dataset for Testing the Model\n",
    "def readTestData(fileName):\n",
    "    row_index=0;\n",
    "    phi=list();\n",
    "    y=list();\n",
    "    with open(fileName) as f:\n",
    "        for line in f:\n",
    "            if row_index >0:\n",
    "                phi_i=list((float(n) for n in line.split('\\n')[0].split(\",\") ));\n",
    "                phi_i[0]=1;\n",
    "                phi.append(phi_i);                             \n",
    "            row_index+=1;\n",
    "    m=len(phi);    \n",
    "    return phi;\n",
    "#End-readTrainData\n",
    "\n",
    "\n",
    "#split train data into Train and Validate\n",
    "def spitTrainDataset(phi,y):\n",
    "    m=len(phi);        \n",
    "    tdsSize=int(m*trainDSSizePercentage);\n",
    "    l=m;\n",
    "    trainDatasetPhi=phi[0:m];\n",
    "    trainDatasetY=y[0:m];\n",
    "    validateDatasetPhi=phi[tdsSize:m];\n",
    "    validateDatasetY=y[tdsSize:m];    \n",
    "   \n",
    "    return [trainDatasetPhi,trainDatasetY,validateDatasetPhi,validateDatasetY];    \n",
    "    pass\n",
    "\n",
    "\n",
    "#write-output\n",
    "def writeTestData(ystar):\n",
    "    fo = open(\"output.csv\", \"w\");    \n",
    "    fo.write(\"ID,MEDV\\n\");\n",
    "    m=len(ystar);\n",
    "    for i in range(m):\n",
    "        fo.write(str(i)+\",\"+str(ystar[i])+\"\\n\");\n",
    "    fo.close();\n",
    "    pass;\n",
    "\n",
    "# Return det of matrix\n",
    "def getDet(A):\n",
    "    d=det(A);\n",
    "    if(d<10**-10):\n",
    "        return 0;\n",
    "    return d;\n",
    "\n",
    "\n",
    "#Return RMS: root mean square error\n",
    "def getRMS(y,yStar):\n",
    "    m=len(y);\n",
    "    sigma=0;\n",
    "    for i in range(m):\n",
    "        delta=(y[i]-yStar[i]);\n",
    "        delta=delta*delta;\n",
    "        sigma=sigma+delta;\n",
    "    meanSq=sigma/m;   \n",
    "    rms=math.sqrt(meanSq);\n",
    "    return rms;\n",
    "    pass;\n",
    "\n",
    "#For ploting graph of RMS VS Iteration\n",
    "def plotGraph(x,y):\n",
    "    import matplotlib.pyplot as plt;\n",
    "    plt.plot(x,y)\n",
    "    plt.ylabel('rms')\n",
    "    plt.xlabel('iteration');\n",
    "    plt.show();\n",
    "    pass;\n",
    "\n",
    "#Record readings for gradient descent\n",
    "def writeReadingInFile(filename,alpha,lam,iteration,rms,p):\n",
    "    import os.path;\n",
    "    import datetime;\n",
    "    import time;\n",
    "    ts = datetime.datetime.fromtimestamp(time.time()).strftime('%d-%m-%Y %H:%M:%S')\n",
    "    if(os.path.exists(filename)==False):\n",
    "        fo = open(filename, \"w\"); \n",
    "        fo.write(\"iteration,norm,alpha,lam,rms,timestamp\\n\");\n",
    "        fo.write(str(iteration)+\",\"+str(p)+\",\"+str(alpha)+\",\"+str(lam)+\",\"+str(rms)+\",\"+str(ts)+\"\\n\");\n",
    "    else:\n",
    "        fo = open(filename, \"a\"); \n",
    "        fo.write(str(iteration)+\",\"+str(p)+\",\"+str(alpha)+\",\"+str(lam)+\",\"+str(rms)+\",\"+str(ts)+\"\\n\");\n",
    "    fo.close();                    \n",
    "    pass;\n",
    "\n",
    "\n",
    "#normalize the data set ny (x-u)/s where s is max-min\n",
    "def normalizePhi(unNormalizedPhi):    \n",
    "    phi=np.array(unNormalizedPhi);\n",
    "    print(\"Normalizing Phi...\");  \n",
    "    std=phi.std(0);\n",
    "    mean=phi.mean(0);    \n",
    "    std[0]=1;\n",
    "    mean[0]=0;\n",
    "    phi_normalize=(phi-mean)/std;    \n",
    "    print(\"Normalization done.\");\n",
    "    return phi_normalize;\n",
    "    pass;\n",
    "\n",
    "#pridict of y* given w* QW=y*\n",
    "def pridict(dataset,weight):\n",
    "    phi=np.array(dataset);\n",
    "    w=np.array(weight);\n",
    "    ystar=np.dot(phi,w);\n",
    "    return ystar;\n",
    "    pass;\n",
    "\n",
    "# Finding w*=(QTQ)^-1QTY\n",
    "def trainUsingClosedFormEquation(dataset,output):\n",
    "    m=len(dataset);\n",
    "    n=len(dataset[0]);\n",
    "    print(\"------------------\");\n",
    "    #print(dataset);\n",
    "    phi=np.array(dataset);\n",
    "    print(\"------------------\");\n",
    "    #print(phi);    \n",
    "    y=np.array(output);\n",
    "    phiT=np.transpose(phi);\n",
    "    #(QTQ)    \n",
    "    phiT_phi=np.dot(phiT,phi);   \n",
    "    d=getDet(phiT_phi)\n",
    "    if(d>0):\n",
    "        #(QTQ)^-1\n",
    "        phiT_phi_inv=inv(phiT_phi);\n",
    "        #(QTQ)^-1QT\n",
    "        phiT_phi_inv_phiT=np.dot(phiT_phi_inv,phiT);  \n",
    "        #(QTQ)^-1QT*Y\n",
    "        w=np.dot(phiT_phi_inv_phiT,y);\n",
    "        return w;\n",
    "    else:\n",
    "        print(\"Error:Phi is NOT full column rank.\");\n",
    "        return None;\n",
    "    pass;\n",
    "\n",
    "# Finding w*=(QTQ+lamI)^-1QTY\n",
    "def trainUsingClosedFormRidgeEq(dataset,output):\n",
    "    m=len(dataset);\n",
    "    n=len(dataset[0]);    \n",
    "    phi=np.array(dataset);\n",
    "    y=np.array(output);\n",
    "    phiT=np.transpose(phi);    \n",
    "    #(QTQ)    \n",
    "    phiT_phi=np.dot(phiT,phi);\n",
    "    n=len(phiT_phi);\n",
    "    lam=0.5;\n",
    "    I=np.identity(n);\n",
    "    lamI=lam*I;\n",
    "    d=getDet(phiT_phi)\n",
    "    #--------------------------------------\n",
    "    if(d>0):\n",
    "        #(QTQ+lamI)^-1\n",
    "        phiT_phi_inv=inv((phiT_phi+.57));\n",
    "        #(QTQ+lamI)^-1QT\n",
    "        phiT_phi_inv_phiT=np.dot(phiT_phi_inv,phiT);  \n",
    "        #(QTQ+lamI)^-1QT*Y\n",
    "        w=np.dot(phiT_phi_inv_phiT,y);\n",
    "        return w;\n",
    "    else:\n",
    "        print(\"Error:Phi is NOT full column rank.\");\n",
    "        return None;\n",
    "    pass;\n",
    "\n",
    "\n",
    "def numpiTestFun():\n",
    "    A2= np.matrix([[4,6],[2,8]])        \n",
    "    A3= np.matrix([[1,2,3],[4,5,7],[7,8,9]])\n",
    "    A=A2;\n",
    "    print(A);\n",
    "    print(np.power(A,0.5));\n",
    "    print(A);\n",
    "    print(\"Det(A):\"+str(getDet(A)));\n",
    "    B= np.transpose(A);\n",
    "    C=inv(A);\n",
    "    #print(C);\n",
    "    print(np.dot(A,C));\n",
    "    print(A.std(0));\n",
    "    print(A.mean(0));\n",
    "    print(normalizePhi(A));\n",
    "    norm=(A-A.mean(0))/A.std(0);    \n",
    "    print(norm);    \n",
    "    print();\n",
    "    pass;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GD: Least Sq. Without Regularlization\n",
    "def gardientDescentErrorFun(phi,y):\n",
    "    m=len(y);#no of data points\n",
    "    n=len(phi[0]);# no. of features    \n",
    "    alpha=0.22;# learning parameter\n",
    "    maxIteration=10000;\n",
    "    phi=np.array(phi);\n",
    "    y=(np.array(y));#converting row vector to col vector    \n",
    "    wk0=np.zeros(n);# Nx1 vector\n",
    "    phiT=np.transpose(phi);\n",
    "    phiTphi=np.dot(phiT,phi);   \n",
    "    phiTy=np.dot(phiT,y);   \n",
    "    alphaBym=alpha/m;\n",
    "    xaxis=list();\n",
    "    yaxis=list();\n",
    "    #----------------------\n",
    "    print(\"Training Started (Least Sq. Without Regularlization) ...\");\n",
    "    for i in range(maxIteration):  \n",
    "        wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)));                \n",
    "        ystar=pridict(phi,wk1);\n",
    "        rms=getRMS(y,ystar);    \n",
    "        xaxis.append(i);\n",
    "        yaxis.append(rms);\n",
    "        percentComplete=((i+1)*100)/maxIteration;\n",
    "        if( percentComplete%10==0 ):\n",
    "            print(\"Percent Completed\",percentComplete);\n",
    "        wk0=wk1;\n",
    "    print(\"Final Trained RMS:\",rms);\n",
    "    plotGraph(xaxis,yaxis);\n",
    "    return wk1;\n",
    "    pass;\n",
    "\n",
    "\n",
    "# GD: Least Sq. With Ridges\n",
    "def gardientDescentWithRidge(phi,y,wi=-1):\n",
    "    m=len(y);#no of data points\n",
    "    n=len(phi[0]);# no. of features    \n",
    "    alpha=0.21;# learning parameter\n",
    "    maxIteration=10000;\n",
    "    phi=np.array(phi);\n",
    "    y=(np.array(y));#converting row vector to col vector    \n",
    "    if(wi==-1):\n",
    "        wk0=np.zeros(n);# Nx1 vector\n",
    "    else:\n",
    "        wk0=phi[wi]\n",
    "    \n",
    "    phiT=np.transpose(phi);\n",
    "    phiTphi=np.dot(phiT,phi);   \n",
    "    phiTy=np.dot(phiT,y);   \n",
    "    alphaBym=alpha/m;\n",
    "    lam=0.301;    \n",
    "    xaxis=list();\n",
    "    yaxis=list();\n",
    "    algFixedIteration=False;\n",
    "    logReading=True;\n",
    "    diff=0;\n",
    "    #-----------------------------------------------------------------\n",
    "    #Best Tested Constant\n",
    "    #aplha=.212 lamda=.301 datasie=0.7 o/p=4.8310 rms\n",
    "    #Tried for different initial wk0 but o/p remain same\n",
    "    #-----------------------------------------------------------------\n",
    "    print(\"Training Started (Least Sq. With Ridge) ...\");\n",
    "    if (algFixedIteration):\n",
    "        for iteration in range(0,maxIteration):  \n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0)));                   \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            percentComplete=((iteration+1)*100)/maxIteration;\n",
    "            if( percentComplete%10==0 ):\n",
    "                print(\"Percent Completed\",percentComplete);\n",
    "            wk0=wk1;\n",
    "    else:\n",
    "        diffOffset=1e-20;\n",
    "        iteration=0;\n",
    "        oldRms=0;\n",
    "        voldRms=0;\n",
    "        while (True):\n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0)));                     \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            diff=abs(oldRms-rms);            \n",
    "            if(iteration>0 and diff<diffOffset):\n",
    "                break;\n",
    "            if(False and iteration%100==0 ):\n",
    "                print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff);            \n",
    "            wk0=wk1;\n",
    "            oldRms=rms;\n",
    "            iteration+=1;\n",
    "        print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff);    \n",
    "           \n",
    "    print(\"Final Trained RMS:\",rms ,\". Iteration needed \", iteration);    \n",
    "    #-------------------------------------------------------------\n",
    "    if(logReading):\n",
    "        writeReadingInFile(\"ridge1.csv\",alpha,lam,iteration,rms,2);\n",
    "    #plotGraph(xaxis,yaxis);\n",
    "    return wk1;\n",
    "\n",
    "def mainRidgeGradientDescent():\n",
    "    print(\"Training started\");\n",
    "    m=len(trainDatasetPhi);\n",
    "    vl=[];\n",
    "    for i in range(m):\n",
    "        wStar=gardientDescentWithRidge(trainDatasetPhi,trainDatasetY,i);\n",
    "        ystar=pridict(validateDatasetPhi,wStar);\n",
    "        #checking for RMS for Validate Data\n",
    "        rms=getRMS(validateDatasetY,ystar);\n",
    "        writeReadingInFile(\"wkridge1.csv\",0,0,i,rms,2);\n",
    "        vl.append(rms)\n",
    "        print(\"Wk=:\",i);\n",
    "    nparr=np.array(vl);\n",
    "    print(\"Completed:\",nparr.min());\n",
    "    pass\n",
    "\n",
    "# GD: Least Sq. With ||w||_(1.5)^(1.5)\n",
    "def gardientDescentWithPnom(phi,y,p):\n",
    "    m=len(y);#no of data points\n",
    "    n=len(phi[0]);# no. of features    \n",
    "    alpha=0.2 #learning parameter\n",
    "    maxIteration=100000;\n",
    "    phi=np.array(phi);\n",
    "    y=(np.array(y));#converting row vector to col vector    \n",
    "    wk0=np.zeros(n);# Nx1 vector    \n",
    "    wk0=phi[1];\n",
    "    phiT=np.transpose(phi);\n",
    "    phiTphi=np.dot(phiT,phi);   \n",
    "    phiTy=np.dot(phiT,y);   \n",
    "    alphaBym=alpha/m;\n",
    "    lam=0.31;\n",
    "    xaxis=list();\n",
    "    yaxis=list();\n",
    "    algFixedIteration=False;\n",
    "    logReading=True;\n",
    "    diff=0;\n",
    "    wPow=p-1;\n",
    "    if (p<=1):\n",
    "        print(\"Error: norm p is less than 1 i.p p=\",wPow);\n",
    "        return None;\n",
    "        \n",
    "    #-----------------------------------------------------------------\n",
    "    print(\"Training Started (Least Sq. With Ridge) ...\");\n",
    "    if (algFixedIteration):\n",
    "        for iteration in range(0,maxIteration):\n",
    "            if (wPow>1):\n",
    "                wk0Pow=np.power(wk0,wPow);            \n",
    "            else:\n",
    "                wk0Pow=wk0;\n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0Pow))); \n",
    "            \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            percentComplete=((iteration+1)*100)/maxIteration;\n",
    "            if( percentComplete%10==0 ):\n",
    "                print(\"Percent Completed\",percentComplete);\n",
    "            wk0=wk1;\n",
    "    else:\n",
    "        diffOffset=1e-20;\n",
    "        iteration=0;\n",
    "        oldRms=0;\n",
    "        voldRms=0;\n",
    "        while (True):            \n",
    "            if (wPow>1):\n",
    "                wk0Pow=np.power(wk0,wPow);            \n",
    "            else:\n",
    "                wk0Pow=wk0;\n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0Pow)));  \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            diff=abs(oldRms-rms);\n",
    "            \n",
    "            vystar=pridict(validateDatasetPhi,wk1);\n",
    "            vrms=getRMS(validateDatasetY,vystar);\n",
    "            vdiff=voldRms-vrms;\n",
    "            \n",
    "            if(iteration>0 and  diff<=diffOffset):\n",
    "                break;\n",
    "            if(False and iteration%100==0 ):\n",
    "                print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff,\" vrms:\",vrms,\" vdiff:\", vdiff);            \n",
    "            wk0=wk1;\n",
    "            oldRms=rms;\n",
    "            voldRms=vrms;\n",
    "            iteration+=1;\n",
    "        print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff,\" vrms:\",vrms,\" vdiff:\", vdiff);    \n",
    "\n",
    "    print(\"Final Trained RMS:\",rms ,\". Iteration needed \", iteration);       \n",
    "    #-------------------------------------------------------------\n",
    "    if(logReading):\n",
    "        writeReadingInFile(\"pnom.csv\",alpha,lam,iteration,rms,p);\n",
    "    plotGraph(xaxis,yaxis);\n",
    "    return wk1; \n",
    "\n",
    "#wStart=gardientDescentWithRidge(trainDatasetPhi,trainDatasetY);\n",
    "#wStart=gardientDescentWithPnom(trainDatasetPhi,trainDatasetY,4);\n",
    "#mainRidgeClosedFormSol();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Trained Dataset from file...\n",
      "Normalizing Phi...\n",
      "Normalization done.\n",
      "Normalizing Phi...\n",
      "Normalization done.\n",
      "Fetching of data Completed.\n",
      "Train Size:400\n",
      "Validate Size:120\n",
      "[[1, 0.9557700000000001, 0.0, 8.14, 0.0, 0.538, 6.047, 88.8, 4.4534, 4.0, 307.0, 21.0, 306.38, 17.28], [1, 0.02875, 28.0, 15.04, 0.0, 0.464, 6.211, 28.9, 3.6659, 4.0, 270.0, 18.2, 396.33, 6.21], [1, 1.22358, 0.0, 19.58, 0.0, 0.605, 6.943, 97.4, 1.8773, 5.0, 403.0, 14.7, 363.43, 4.59], [1, 5.66637, 0.0, 18.1, 0.0, 0.74, 6.219, 100.0, 2.0048, 24.0, 666.0, 20.2, 395.69, 16.59], [1, 0.045439999999999994, 0.0, 3.24, 0.0, 0.46, 6.144, 32.2, 5.8736, 4.0, 430.0, 16.9, 368.57, 9.09], [1, 0.10659, 80.0, 1.91, 0.0, 0.413, 5.936, 19.5, 10.5857, 4.0, 334.0, 22.0, 376.04, 5.57], [1, 51.1358, 0.0, 18.1, 0.0, 0.597, 5.757, 100.0, 1.413, 24.0, 666.0, 20.2, 2.6, 10.11], [1, 3.32105, 0.0, 19.58, 1.0, 0.871, 5.403, 100.0, 1.3216, 5.0, 403.0, 14.7, 396.9, 26.82], [1, 1.05393, 0.0, 8.14, 0.0, 0.538, 5.935, 29.3, 4.4986, 4.0, 307.0, 21.0, 386.85, 6.58], [1, 0.24522, 0.0, 9.9, 0.0, 0.544, 5.782, 71.7, 4.0317, 4.0, 304.0, 18.4, 396.9, 15.94], [1, 0.57834, 20.0, 3.97, 0.0, 0.575, 8.297, 67.0, 2.4216, 5.0, 264.0, 13.0, 384.54, 7.44], [1, 0.03537, 34.0, 6.09, 0.0, 0.433, 6.59, 40.4, 5.4917, 7.0, 329.0, 16.1, 395.75, 9.5], [1, 3.8497, 0.0, 18.1, 1.0, 0.77, 6.395, 91.0, 2.5052, 24.0, 666.0, 20.2, 391.34, 13.27], [1, 38.3518, 0.0, 18.1, 0.0, 0.693, 5.453, 100.0, 1.4896, 24.0, 666.0, 20.2, 396.9, 30.59], [1, 0.35809, 0.0, 6.2, 1.0, 0.507, 6.951, 88.5, 2.8617, 8.0, 307.0, 17.4, 391.7, 9.71], [1, 15.8603, 0.0, 18.1, 0.0, 0.679, 5.896, 95.4, 1.9096, 24.0, 666.0, 20.2, 7.68, 24.39], [1, 6.44405, 0.0, 18.1, 0.0, 0.584, 6.425, 74.8, 2.2004, 24.0, 666.0, 20.2, 97.95, 12.03], [1, 5.82115, 0.0, 18.1, 0.0, 0.713, 6.513, 89.9, 2.8016, 24.0, 666.0, 20.2, 393.82, 10.29], [1, 0.035019999999999996, 80.0, 4.95, 0.0, 0.411, 6.861, 27.9, 5.1167, 4.0, 245.0, 19.2, 396.9, 3.33], [1, 12.0482, 0.0, 18.1, 0.0, 0.614, 5.648, 87.6, 1.9512, 24.0, 666.0, 20.2, 291.55, 14.1], [1, 0.06663999999999999, 0.0, 4.05, 0.0, 0.51, 6.546, 33.1, 3.1323, 5.0, 296.0, 16.6, 390.96, 5.33], [1, 0.537, 0.0, 6.2, 0.0, 0.504, 5.981, 68.1, 3.6715, 8.0, 307.0, 17.4, 378.35, 11.65], [1, 0.55778, 0.0, 21.89, 0.0, 0.624, 6.335, 98.2, 2.1107, 4.0, 437.0, 21.2, 394.67, 16.96], [1, 0.7904100000000001, 0.0, 9.9, 0.0, 0.544, 6.122, 52.8, 2.6403, 4.0, 304.0, 18.4, 396.9, 5.98], [1, 0.33045, 0.0, 6.2, 0.0, 0.507, 6.086, 61.5, 3.6519, 8.0, 307.0, 17.4, 376.75, 10.88], [1, 0.06588, 0.0, 2.46, 0.0, 0.488, 7.765, 83.3, 2.741, 3.0, 193.0, 17.8, 395.56, 7.56], [1, 0.77299, 0.0, 8.14, 0.0, 0.538, 6.495, 94.4, 4.4547, 4.0, 307.0, 21.0, 387.94, 12.8], [1, 0.053720000000000004, 0.0, 13.92, 0.0, 0.437, 6.549, 51.0, 5.9604, 4.0, 289.0, 16.0, 392.85, 7.39], [1, 0.08265, 0.0, 13.92, 0.0, 0.437, 6.127, 18.4, 5.5027, 4.0, 289.0, 16.0, 396.9, 8.58], [1, 0.16439, 22.0, 5.86, 0.0, 0.431, 6.433, 49.1, 7.8265, 7.0, 330.0, 19.1, 374.71, 9.52], [1, 3.6736699999999995, 0.0, 18.1, 0.0, 0.583, 6.312, 51.9, 3.9917, 24.0, 666.0, 20.2, 388.62, 10.58], [1, 0.34006, 0.0, 21.89, 0.0, 0.624, 6.458, 98.9, 2.1185, 4.0, 437.0, 21.2, 395.04, 12.6], [1, 0.09744, 0.0, 5.96, 0.0, 0.499, 5.841, 61.4, 3.3779, 5.0, 279.0, 19.2, 377.56, 11.41], [1, 0.06047, 0.0, 2.46, 0.0, 0.488, 6.153, 68.8, 3.2797, 3.0, 193.0, 17.8, 387.11, 13.15], [1, 5.69175, 0.0, 18.1, 0.0, 0.583, 6.114, 79.8, 3.5459, 24.0, 666.0, 20.2, 392.68, 14.98], [1, 24.3938, 0.0, 18.1, 0.0, 0.7, 4.652, 100.0, 1.4672, 24.0, 666.0, 20.2, 396.9, 28.28], [1, 0.14052, 0.0, 10.59, 0.0, 0.489, 6.375, 32.3, 3.9454, 4.0, 277.0, 18.6, 385.81, 9.38], [1, 0.05561, 70.0, 2.24, 0.0, 0.4, 7.041, 10.0, 7.8278, 5.0, 358.0, 14.8, 371.58, 4.74], [1, 0.12816, 12.5, 6.07, 0.0, 0.409, 5.885, 33.0, 6.498, 4.0, 345.0, 18.9, 396.9, 8.79], [1, 2.37857, 0.0, 18.1, 0.0, 0.583, 5.871, 41.9, 3.724, 24.0, 666.0, 20.2, 370.73, 13.34], [1, 0.06911, 45.0, 3.44, 0.0, 0.437, 6.739, 30.8, 6.4798, 5.0, 398.0, 15.2, 389.71, 4.69], [1, 0.21719000000000002, 0.0, 10.59, 1.0, 0.489, 5.807, 53.8, 3.6526, 4.0, 277.0, 18.6, 390.94, 16.03], [1, 0.5401100000000001, 20.0, 3.97, 0.0, 0.647, 7.203, 81.8, 2.1121, 5.0, 264.0, 13.0, 392.8, 9.59], [1, 0.22926999999999997, 0.0, 6.91, 0.0, 0.448, 6.03, 85.5, 5.6894, 3.0, 233.0, 17.9, 392.74, 18.8], [1, 0.05479, 33.0, 2.18, 0.0, 0.472, 6.616, 58.1, 3.37, 7.0, 222.0, 18.4, 393.36, 8.93], [1, 0.8520399999999999, 0.0, 8.14, 0.0, 0.538, 5.965, 89.2, 4.0123, 4.0, 307.0, 21.0, 392.53, 13.83], [1, 0.049319999999999996, 33.0, 2.18, 0.0, 0.472, 6.849, 70.3, 3.1827, 7.0, 222.0, 18.4, 396.9, 7.53], [1, 8.20058, 0.0, 18.1, 0.0, 0.713, 5.936, 80.3, 2.7792, 24.0, 666.0, 20.2, 3.5, 16.94], [1, 8.98296, 0.0, 18.1, 1.0, 0.77, 6.212, 97.4, 2.1222, 24.0, 666.0, 20.2, 377.73, 17.6], [1, 7.022589999999999, 0.0, 18.1, 0.0, 0.718, 6.006, 95.3, 1.8746, 24.0, 666.0, 20.2, 319.98, 15.7], [1, 13.6781, 0.0, 18.1, 0.0, 0.74, 5.935, 87.9, 1.8206, 24.0, 666.0, 20.2, 68.95, 34.02], [1, 2.4466799999999997, 0.0, 19.58, 0.0, 0.871, 5.272, 94.0, 1.7364, 5.0, 403.0, 14.7, 88.63, 16.14], [1, 1.12658, 0.0, 19.58, 1.0, 0.871, 5.012, 88.0, 1.6102, 5.0, 403.0, 14.7, 343.28, 12.12], [1, 0.062110000000000005, 40.0, 1.25, 0.0, 0.429, 6.49, 44.4, 8.7921, 1.0, 335.0, 19.7, 396.9, 5.98], [1, 4.8356699999999995, 0.0, 18.1, 0.0, 0.583, 5.905, 53.2, 3.1523, 24.0, 666.0, 20.2, 388.22, 11.45], [1, 0.25387, 0.0, 6.91, 0.0, 0.448, 5.399, 95.3, 5.87, 3.0, 233.0, 17.9, 396.9, 30.81], [1, 0.22969, 0.0, 10.59, 0.0, 0.489, 6.326, 52.5, 4.3549, 4.0, 277.0, 18.6, 394.87, 10.97], [1, 0.06262999999999999, 0.0, 11.93, 0.0, 0.573, 6.593, 69.1, 2.4786, 1.0, 273.0, 21.0, 391.99, 9.67], [1, 0.01439, 60.0, 2.93, 0.0, 0.401, 6.604, 18.8, 6.2196, 1.0, 265.0, 15.6, 376.7, 4.38], [1, 0.15098, 0.0, 10.01, 0.0, 0.547, 6.021, 82.6, 2.7474, 6.0, 432.0, 17.8, 394.51, 10.3], [1, 0.08014, 0.0, 5.96, 0.0, 0.499, 5.85, 41.5, 3.9342, 5.0, 279.0, 19.2, 396.9, 8.77], [1, 22.5971, 0.0, 18.1, 0.0, 0.7, 5.0, 89.5, 1.5184, 24.0, 666.0, 20.2, 396.9, 31.99], [1, 28.6558, 0.0, 18.1, 0.0, 0.597, 5.155, 100.0, 1.5894, 24.0, 666.0, 20.2, 210.97, 20.08], [1, 0.09378, 12.5, 7.87, 0.0, 0.524, 5.889, 39.0, 5.4509, 5.0, 311.0, 15.2, 390.5, 15.71], [1, 0.67191, 0.0, 8.14, 0.0, 0.538, 5.813, 90.3, 4.682, 4.0, 307.0, 21.0, 376.88, 14.81], [1, 0.3494, 0.0, 9.9, 0.0, 0.544, 5.972, 76.7, 3.1025, 4.0, 304.0, 18.4, 396.24, 9.97], [1, 0.22211999999999998, 0.0, 10.01, 0.0, 0.547, 6.092, 95.4, 2.548, 6.0, 432.0, 17.8, 396.9, 17.09], [1, 0.10574000000000001, 0.0, 27.74, 0.0, 0.609, 5.983, 98.8, 1.8681, 4.0, 711.0, 20.1, 390.11, 18.07], [1, 0.13262000000000002, 0.0, 8.56, 0.0, 0.52, 5.851, 96.7, 2.1069, 5.0, 384.0, 20.9, 394.05, 16.47], [1, 0.62356, 0.0, 6.2, 1.0, 0.507, 6.879, 77.7, 3.2721, 8.0, 307.0, 17.4, 390.39, 9.93], [1, 2.2423599999999997, 0.0, 19.58, 0.0, 0.605, 5.854, 91.8, 2.422, 5.0, 403.0, 14.7, 395.11, 11.64], [1, 0.015009999999999999, 80.0, 2.01, 0.0, 0.435, 6.635, 29.7, 8.344, 4.0, 280.0, 17.0, 390.94, 5.99], [1, 0.11747, 12.5, 7.87, 0.0, 0.524, 6.009, 82.9, 6.2267, 5.0, 311.0, 15.2, 396.9, 13.27], [1, 19.6091, 0.0, 18.1, 0.0, 0.671, 7.313, 97.9, 1.3163, 24.0, 666.0, 20.2, 396.9, 13.44], [1, 0.76162, 20.0, 3.97, 0.0, 0.647, 5.56, 62.8, 1.9865, 5.0, 264.0, 13.0, 392.4, 10.45], [1, 8.26725, 0.0, 18.1, 1.0, 0.668, 5.875, 89.6, 1.1296, 24.0, 666.0, 20.2, 347.88, 8.88], [1, 0.21409, 22.0, 5.86, 0.0, 0.431, 6.438, 8.9, 7.3967, 7.0, 330.0, 19.1, 377.07, 3.59], [1, 0.30346999999999996, 0.0, 7.38, 0.0, 0.493, 6.312, 28.9, 5.4159, 5.0, 287.0, 19.6, 396.9, 6.15], [1, 0.09164, 0.0, 10.81, 0.0, 0.413, 6.065, 7.8, 5.2873, 4.0, 305.0, 19.2, 390.91, 5.52], [1, 0.04527, 0.0, 11.93, 0.0, 0.573, 6.12, 76.7, 2.2875, 1.0, 273.0, 21.0, 396.9, 9.08], [1, 18.4982, 0.0, 18.1, 0.0, 0.668, 4.138, 100.0, 1.137, 24.0, 666.0, 20.2, 396.9, 37.97], [1, 0.82526, 20.0, 3.97, 0.0, 0.647, 7.327, 94.5, 2.0788, 5.0, 264.0, 13.0, 393.42, 11.25], [1, 0.03932, 0.0, 3.41, 0.0, 0.489, 6.405, 73.9, 3.0921, 2.0, 270.0, 17.8, 393.55, 8.2], [1, 0.05644, 40.0, 6.41, 1.0, 0.447, 6.758, 32.9, 4.0776, 4.0, 254.0, 17.6, 396.9, 3.53], [1, 0.19133, 22.0, 5.86, 0.0, 0.431, 5.605, 70.2, 7.9549, 7.0, 330.0, 19.1, 389.13, 18.46], [1, 0.57529, 0.0, 6.2, 0.0, 0.507, 8.337, 73.3, 3.8384, 8.0, 307.0, 17.4, 385.91, 2.47], [1, 0.7857, 20.0, 3.97, 0.0, 0.647, 7.014, 84.6, 2.1329, 5.0, 264.0, 13.0, 384.07, 14.79], [1, 0.01709, 90.0, 2.02, 0.0, 0.41, 6.728, 36.1, 12.1265, 5.0, 187.0, 17.0, 384.46, 4.5], [1, 25.9406, 0.0, 18.1, 0.0, 0.679, 5.304, 89.1, 1.6475, 24.0, 666.0, 20.2, 127.36, 26.64], [1, 20.0849, 0.0, 18.1, 0.0, 0.7, 4.368, 91.2, 1.4395, 24.0, 666.0, 20.2, 285.83, 30.63], [1, 0.0187, 85.0, 4.15, 0.0, 0.429, 6.516, 27.7, 8.5353, 4.0, 351.0, 17.9, 392.43, 6.36], [1, 0.02985, 0.0, 2.18, 0.0, 0.458, 6.43, 58.7, 6.0622, 3.0, 222.0, 18.7, 394.12, 5.21], [1, 0.5341199999999999, 20.0, 3.97, 0.0, 0.647, 7.52, 89.4, 2.1398, 5.0, 264.0, 13.0, 388.37, 7.26], [1, 0.04462, 25.0, 4.86, 0.0, 0.426, 6.619, 70.4, 5.4007, 4.0, 281.0, 19.0, 395.63, 7.22], [1, 0.19539, 0.0, 10.81, 0.0, 0.413, 6.245, 6.2, 5.2873, 4.0, 305.0, 19.2, 377.17, 7.54], [1, 1.15172, 0.0, 8.14, 0.0, 0.538, 5.701, 95.0, 3.7872, 4.0, 307.0, 21.0, 358.77, 18.35], [1, 0.02055, 85.0, 0.74, 0.0, 0.41, 6.383, 35.7, 9.1876, 2.0, 313.0, 17.3, 396.9, 5.77], [1, 2.63548, 0.0, 9.9, 0.0, 0.544, 4.973, 37.8, 2.5194, 4.0, 304.0, 18.4, 350.45, 12.64], [1, 0.41238, 0.0, 6.2, 0.0, 0.504, 7.163, 79.9, 3.2157, 8.0, 307.0, 17.4, 372.08, 6.36], [1, 0.08826, 0.0, 10.81, 0.0, 0.413, 6.417, 6.6, 5.2873, 4.0, 305.0, 19.2, 383.73, 6.72], [1, 0.05735, 0.0, 4.49, 0.0, 0.449, 6.63, 56.1, 4.4377, 3.0, 247.0, 18.5, 392.3, 6.53], [1, 0.027630000000000002, 75.0, 2.95, 0.0, 0.428, 6.595, 21.8, 5.4011, 3.0, 252.0, 18.3, 395.63, 4.32], [1, 0.18836, 0.0, 6.91, 0.0, 0.448, 5.786, 33.3, 5.1004, 3.0, 233.0, 17.9, 396.9, 14.15], [1, 0.20608, 22.0, 5.86, 0.0, 0.431, 5.593, 76.5, 7.9549, 7.0, 330.0, 19.1, 372.49, 12.5], [1, 0.03659, 25.0, 4.86, 0.0, 0.426, 6.302, 32.2, 5.4007, 4.0, 281.0, 19.0, 396.9, 6.72], [1, 0.6147, 0.0, 6.2, 0.0, 0.507, 6.618, 80.8, 3.2721, 8.0, 307.0, 17.4, 396.9, 7.6], [1, 0.22188000000000002, 20.0, 6.96, 1.0, 0.464, 7.691, 51.8, 4.3665, 3.0, 223.0, 18.6, 390.77, 6.58], [1, 88.9762, 0.0, 18.1, 0.0, 0.671, 6.968, 91.9, 1.4165, 24.0, 666.0, 20.2, 396.9, 17.21], [1, 24.8017, 0.0, 18.1, 0.0, 0.693, 5.349, 96.0, 1.7028, 24.0, 666.0, 20.2, 396.9, 19.77], [1, 0.08447, 0.0, 4.05, 0.0, 0.51, 5.859, 68.7, 2.7019, 5.0, 296.0, 16.6, 393.23, 9.64], [1, 8.15174, 0.0, 18.1, 0.0, 0.7, 5.39, 98.9, 1.7281, 24.0, 666.0, 20.2, 396.9, 20.85], [1, 0.07013, 0.0, 13.89, 0.0, 0.55, 6.642, 85.1, 3.4211, 5.0, 276.0, 16.4, 392.78, 9.69], [1, 0.07503, 33.0, 2.18, 0.0, 0.472, 7.42, 71.9, 3.0992, 7.0, 222.0, 18.4, 396.9, 6.47], [1, 0.31533, 0.0, 6.2, 0.0, 0.504, 8.266, 78.3, 2.8944, 8.0, 307.0, 17.4, 385.05, 4.14], [1, 0.55007, 20.0, 3.97, 0.0, 0.647, 7.206, 91.6, 1.9301, 5.0, 264.0, 13.0, 387.89, 8.1], [1, 0.03584, 80.0, 3.37, 0.0, 0.398, 6.29, 17.8, 6.6115, 4.0, 337.0, 16.1, 396.9, 4.67], [1, 15.288, 0.0, 18.1, 0.0, 0.671, 6.649, 93.3, 1.3449, 24.0, 666.0, 20.2, 363.02, 23.24], [1, 0.01778, 95.0, 1.47, 0.0, 0.403, 7.135, 13.9, 7.6534, 3.0, 402.0, 17.0, 384.3, 4.45], [1, 2.7797400000000003, 0.0, 19.58, 0.0, 0.871, 4.903, 97.8, 1.3459, 5.0, 403.0, 14.7, 396.9, 29.29], [1, 9.18702, 0.0, 18.1, 0.0, 0.7, 5.536, 100.0, 1.5804, 24.0, 666.0, 20.2, 396.9, 23.6], [1, 13.9134, 0.0, 18.1, 0.0, 0.713, 6.208, 95.0, 2.2222, 24.0, 666.0, 20.2, 100.63, 15.17], [1, 9.72418, 0.0, 18.1, 0.0, 0.74, 6.406, 97.2, 2.0651, 24.0, 666.0, 20.2, 385.96, 19.52], [1, 0.07875, 45.0, 3.44, 0.0, 0.437, 6.782, 41.1, 3.7886, 5.0, 398.0, 15.2, 393.87, 6.68], [1, 3.1636, 0.0, 18.1, 0.0, 0.655, 5.759, 48.2, 3.0665, 24.0, 666.0, 20.2, 334.4, 14.13], [1, 0.11069000000000001, 0.0, 13.89, 1.0, 0.55, 5.951, 93.8, 2.8893, 5.0, 276.0, 16.4, 396.9, 17.92], [1, 0.17446, 0.0, 10.59, 1.0, 0.489, 5.96, 92.1, 3.8771, 4.0, 277.0, 18.6, 393.25, 17.27], [1, 0.66351, 20.0, 3.97, 0.0, 0.647, 7.333, 100.0, 1.8946, 5.0, 264.0, 13.0, 383.29, 7.79], [1, 0.01381, 80.0, 0.46, 0.0, 0.422, 7.875, 32.0, 5.6484, 4.0, 255.0, 14.4, 394.23, 2.97], [1, 11.1081, 0.0, 18.1, 0.0, 0.668, 4.906, 100.0, 1.1742, 24.0, 666.0, 20.2, 396.9, 34.77], [1, 0.04113, 25.0, 4.86, 0.0, 0.426, 6.727, 33.5, 5.4007, 4.0, 281.0, 19.0, 396.9, 5.29], [1, 1.8337700000000001, 0.0, 19.58, 1.0, 0.605, 7.802, 98.2, 2.0407, 5.0, 403.0, 14.7, 389.61, 1.92], [1, 0.33147, 0.0, 6.2, 0.0, 0.507, 8.247, 70.4, 3.6519, 8.0, 307.0, 17.4, 378.95, 3.95], [1, 0.2498, 0.0, 21.89, 0.0, 0.624, 5.857, 98.2, 1.6686, 4.0, 437.0, 21.2, 392.04, 21.32], [1, 0.12802, 0.0, 8.56, 0.0, 0.52, 6.474, 97.1, 2.4329, 5.0, 384.0, 20.9, 395.24, 12.27], [1, 0.35114, 0.0, 7.38, 0.0, 0.493, 6.041, 49.9, 4.7211, 5.0, 287.0, 19.6, 396.9, 7.7], [1, 9.39063, 0.0, 18.1, 0.0, 0.74, 5.627, 93.9, 1.8172, 24.0, 666.0, 20.2, 396.9, 22.88], [1, 14.3337, 0.0, 18.1, 0.0, 0.614, 6.229, 88.0, 1.9512, 24.0, 666.0, 20.2, 383.32, 13.11], [1, 0.037380000000000004, 0.0, 5.19, 0.0, 0.515, 6.31, 38.5, 6.4584, 5.0, 224.0, 20.2, 389.4, 6.75], [1, 0.08199, 0.0, 13.92, 0.0, 0.437, 6.009, 42.3, 5.5027, 4.0, 289.0, 16.0, 396.9, 10.4], [1, 4.03841, 0.0, 18.1, 0.0, 0.532, 6.229, 90.7, 3.0993, 24.0, 666.0, 20.2, 395.33, 12.87], [1, 0.54452, 0.0, 21.89, 0.0, 0.624, 6.151, 97.9, 1.6687, 4.0, 437.0, 21.2, 396.9, 18.46], [1, 0.16902, 0.0, 25.65, 0.0, 0.581, 5.986, 88.4, 1.9929, 2.0, 188.0, 19.1, 385.02, 14.81], [1, 0.043789999999999996, 80.0, 3.37, 0.0, 0.398, 5.787, 31.1, 6.6115, 4.0, 337.0, 16.1, 396.9, 10.24], [1, 4.64689, 0.0, 18.1, 0.0, 0.614, 6.98, 67.6, 2.5329, 24.0, 666.0, 20.2, 374.68, 11.66], [1, 8.24809, 0.0, 18.1, 0.0, 0.713, 7.393, 99.3, 2.4527, 24.0, 666.0, 20.2, 375.87, 16.74], [1, 3.56868, 0.0, 18.1, 0.0, 0.58, 6.437, 75.0, 2.8965, 24.0, 666.0, 20.2, 393.37, 14.36], [1, 4.0974, 0.0, 19.58, 0.0, 0.871, 5.468, 100.0, 1.4118, 5.0, 403.0, 14.7, 396.9, 26.42], [1, 4.898219999999999, 0.0, 18.1, 0.0, 0.631, 4.97, 100.0, 1.3325, 24.0, 666.0, 20.2, 375.52, 3.26], [1, 0.1146, 20.0, 6.96, 0.0, 0.464, 6.538, 58.7, 3.9175, 3.0, 223.0, 18.6, 394.96, 7.73], [1, 6.39312, 0.0, 18.1, 0.0, 0.584, 6.162, 97.4, 2.206, 24.0, 666.0, 20.2, 302.76, 24.1], [1, 0.11425, 0.0, 13.89, 1.0, 0.55, 6.373, 92.4, 3.3633, 5.0, 276.0, 16.4, 393.74, 10.5], [1, 0.0837, 45.0, 3.44, 0.0, 0.437, 7.185, 38.9, 4.5667, 5.0, 398.0, 15.2, 396.9, 5.39], [1, 0.12579, 45.0, 3.44, 0.0, 0.437, 6.556, 29.1, 4.5667, 5.0, 398.0, 15.2, 382.84, 4.56], [1, 11.1604, 0.0, 18.1, 0.0, 0.74, 6.629, 94.6, 2.1247, 24.0, 666.0, 20.2, 109.85, 23.27], [1, 0.11027, 25.0, 5.13, 0.0, 0.453, 6.456, 67.8, 7.2255, 8.0, 284.0, 19.7, 396.9, 6.73], [1, 0.26169000000000003, 0.0, 9.9, 0.0, 0.544, 6.023, 90.4, 2.834, 4.0, 304.0, 18.4, 396.3, 11.72], [1, 0.032369999999999996, 0.0, 2.18, 0.0, 0.458, 6.998, 45.8, 6.0622, 3.0, 222.0, 18.7, 394.63, 2.94], [1, 14.3337, 0.0, 18.1, 0.0, 0.7, 4.88, 100.0, 1.5895, 24.0, 666.0, 20.2, 372.92, 30.62], [1, 0.08387, 0.0, 12.83, 0.0, 0.437, 5.874, 36.6, 4.5026, 5.0, 398.0, 18.7, 396.06, 9.1], [1, 0.19657, 22.0, 5.86, 0.0, 0.431, 6.226, 79.2, 8.0555, 7.0, 330.0, 19.1, 376.14, 10.15], [1, 2.36862, 0.0, 19.58, 0.0, 0.871, 4.926, 95.7, 1.4608, 5.0, 403.0, 14.7, 391.71, 29.53], [1, 12.8023, 0.0, 18.1, 0.0, 0.74, 5.854, 96.6, 1.8956, 24.0, 666.0, 20.2, 240.52, 23.79], [1, 1.2074200000000002, 0.0, 19.58, 0.0, 0.605, 5.875, 94.6, 2.4259, 5.0, 403.0, 14.7, 292.29, 14.43], [1, 0.04297, 52.5, 5.32, 0.0, 0.405, 6.565, 22.9, 7.3172, 6.0, 293.0, 16.6, 371.72, 9.51], [1, 8.49213, 0.0, 18.1, 0.0, 0.584, 6.348, 86.1, 2.0527, 24.0, 666.0, 20.2, 83.45, 17.64], [1, 0.32982, 0.0, 21.89, 0.0, 0.624, 5.822, 95.4, 2.4699, 4.0, 437.0, 21.2, 388.69, 15.03], [1, 15.1772, 0.0, 18.1, 0.0, 0.74, 6.152, 100.0, 1.9142, 24.0, 666.0, 20.2, 9.32, 26.45], [1, 0.03871, 52.5, 5.32, 0.0, 0.405, 6.209, 31.3, 7.3172, 6.0, 293.0, 16.6, 396.9, 7.14], [1, 2.4495299999999998, 0.0, 19.58, 0.0, 0.605, 6.402, 95.2, 2.2625, 5.0, 403.0, 14.7, 330.04, 11.32], [1, 0.06417, 0.0, 5.96, 0.0, 0.499, 5.933, 68.2, 3.3603, 5.0, 279.0, 19.2, 396.9, 9.68], [1, 0.25199, 0.0, 10.59, 0.0, 0.489, 5.783, 72.7, 4.3549, 4.0, 277.0, 18.6, 389.43, 18.06], [1, 0.12204000000000001, 0.0, 2.89, 0.0, 0.445, 6.625, 57.8, 3.4952, 2.0, 276.0, 18.0, 357.98, 6.65], [1, 0.43571000000000004, 0.0, 10.59, 1.0, 0.489, 5.344, 100.0, 3.875, 4.0, 277.0, 18.6, 396.9, 23.09], [1, 0.17899, 0.0, 9.69, 0.0, 0.585, 5.67, 28.8, 2.7986, 6.0, 391.0, 19.2, 393.29, 17.6], [1, 10.233, 0.0, 18.1, 0.0, 0.614, 6.185, 96.7, 2.1705, 24.0, 666.0, 20.2, 379.7, 18.03], [1, 0.44791000000000003, 0.0, 6.2, 1.0, 0.507, 6.726, 66.5, 3.6519, 8.0, 307.0, 17.4, 360.2, 8.05], [1, 0.13914, 0.0, 4.05, 0.0, 0.51, 5.572, 88.5, 2.5961, 5.0, 296.0, 16.6, 396.9, 14.69], [1, 0.11329000000000002, 30.0, 4.93, 0.0, 0.428, 6.897, 54.3, 6.3361, 6.0, 300.0, 16.6, 391.25, 11.38], [1, 0.09252, 30.0, 4.93, 0.0, 0.428, 6.606, 42.2, 6.1899, 6.0, 300.0, 16.6, 383.78, 7.37], [1, 0.035480000000000005, 80.0, 3.64, 0.0, 0.392, 5.876, 19.1, 9.2203, 1.0, 315.0, 16.4, 395.18, 9.25], [1, 5.5810699999999995, 0.0, 18.1, 0.0, 0.713, 6.436, 87.9, 2.3158, 24.0, 666.0, 20.2, 100.19, 16.22], [1, 0.22438000000000002, 0.0, 9.69, 0.0, 0.585, 6.027, 79.7, 2.4982, 6.0, 391.0, 19.2, 396.9, 14.33], [1, 0.07896, 0.0, 12.83, 0.0, 0.437, 6.273, 6.0, 4.2515, 5.0, 398.0, 18.7, 394.92, 6.78], [1, 0.61154, 20.0, 3.97, 0.0, 0.647, 8.704, 86.9, 1.801, 5.0, 264.0, 13.0, 389.7, 5.12], [1, 0.38214000000000004, 0.0, 6.2, 0.0, 0.504, 8.04, 86.5, 3.2157, 8.0, 307.0, 17.4, 387.38, 3.13], [1, 3.69695, 0.0, 18.1, 0.0, 0.718, 4.963, 91.4, 1.7523, 24.0, 666.0, 20.2, 316.03, 14.0], [1, 5.8240099999999995, 0.0, 18.1, 0.0, 0.532, 6.242, 64.7, 3.4242, 24.0, 666.0, 20.2, 396.9, 10.74], [1, 0.09065, 20.0, 6.96, 1.0, 0.464, 5.92, 61.5, 3.9175, 3.0, 223.0, 18.6, 391.34, 13.65], [1, 0.0315, 95.0, 1.47, 0.0, 0.403, 6.975, 15.3, 7.6534, 3.0, 402.0, 17.0, 396.9, 4.56], [1, 3.69311, 0.0, 18.1, 0.0, 0.713, 6.376, 88.4, 2.5671, 24.0, 666.0, 20.2, 391.43, 14.65], [1, 9.82349, 0.0, 18.1, 0.0, 0.671, 6.794, 98.8, 1.358, 24.0, 666.0, 20.2, 396.9, 21.24], [1, 0.01965, 80.0, 1.76, 0.0, 0.385, 6.23, 31.5, 9.0892, 1.0, 241.0, 18.2, 341.6, 12.93], [1, 0.28392, 0.0, 7.38, 0.0, 0.493, 5.708, 74.3, 4.7211, 5.0, 287.0, 19.6, 391.13, 11.74], [1, 2.15505, 0.0, 19.58, 0.0, 0.871, 5.628, 100.0, 1.5166, 5.0, 403.0, 14.7, 169.27, 16.65], [1, 0.9884299999999999, 0.0, 8.14, 0.0, 0.538, 5.813, 100.0, 4.0952, 4.0, 307.0, 21.0, 394.54, 19.88], [1, 0.17134000000000002, 0.0, 10.01, 0.0, 0.547, 5.928, 88.2, 2.4631, 6.0, 432.0, 17.8, 344.91, 15.76], [1, 0.07151, 0.0, 4.49, 0.0, 0.449, 6.121, 56.8, 3.7476, 3.0, 247.0, 18.5, 395.15, 8.44], [1, 0.0795, 60.0, 1.69, 0.0, 0.411, 6.579, 35.9, 10.7103, 4.0, 411.0, 18.3, 370.78, 5.49], [1, 1.25179, 0.0, 8.14, 0.0, 0.538, 5.57, 98.1, 3.7979, 4.0, 307.0, 21.0, 376.57, 21.02], [1, 0.01311, 90.0, 1.22, 0.0, 0.403, 7.249, 21.9, 8.6966, 5.0, 226.0, 17.9, 395.93, 4.81], [1, 0.03768, 80.0, 1.52, 0.0, 0.404, 7.274, 38.3, 7.309, 2.0, 329.0, 12.6, 392.2, 6.62], [1, 0.17783, 0.0, 9.69, 0.0, 0.585, 5.569, 73.5, 2.3999, 6.0, 391.0, 19.2, 395.77, 15.1], [1, 8.71675, 0.0, 18.1, 0.0, 0.693, 6.471, 98.8, 1.7257, 24.0, 666.0, 20.2, 391.98, 17.12], [1, 5.44114, 0.0, 18.1, 0.0, 0.713, 6.655, 98.2, 2.3552, 24.0, 666.0, 20.2, 355.29, 17.73], [1, 0.49298000000000003, 0.0, 9.9, 0.0, 0.544, 6.635, 82.5, 3.3175, 4.0, 304.0, 18.4, 396.9, 4.54], [1, 4.87141, 0.0, 18.1, 0.0, 0.614, 6.484, 93.6, 2.3053, 24.0, 666.0, 20.2, 396.21, 18.68], [1, 0.1265, 25.0, 5.13, 0.0, 0.453, 6.762, 43.4, 7.9809, 8.0, 284.0, 19.7, 395.58, 9.5], [1, 0.03578, 20.0, 3.33, 0.0, 0.4429, 7.82, 64.5, 4.6947, 5.0, 216.0, 14.9, 387.31, 3.76], [1, 0.0578, 0.0, 2.46, 0.0, 0.488, 6.98, 58.4, 2.829, 3.0, 193.0, 17.8, 396.9, 5.04], [1, 0.03306, 0.0, 5.19, 0.0, 0.515, 6.059, 37.3, 4.8122, 5.0, 224.0, 20.2, 396.14, 8.51], [1, 5.09017, 0.0, 18.1, 0.0, 0.713, 6.297, 91.8, 2.3682, 24.0, 666.0, 20.2, 385.09, 17.27], [1, 2.7339700000000002, 0.0, 19.58, 0.0, 0.871, 5.597, 94.9, 1.5257, 5.0, 403.0, 14.7, 351.85, 21.45], [1, 3.7749800000000002, 0.0, 18.1, 0.0, 0.655, 5.952, 84.7, 2.8715, 24.0, 666.0, 20.2, 22.01, 17.15], [1, 0.29819, 0.0, 6.2, 0.0, 0.504, 7.686, 17.0, 3.3751, 8.0, 307.0, 17.4, 377.51, 3.92], [1, 6.80117, 0.0, 18.1, 0.0, 0.713, 6.081, 84.4, 2.7175, 24.0, 666.0, 20.2, 396.9, 14.7], [1, 0.08872999999999999, 21.0, 5.64, 0.0, 0.439, 5.963, 45.7, 6.8147, 4.0, 243.0, 16.8, 395.56, 13.45], [1, 1.38799, 0.0, 8.14, 0.0, 0.538, 5.95, 82.0, 3.99, 4.0, 307.0, 21.0, 232.6, 27.71], [1, 0.030489999999999996, 55.0, 3.78, 0.0, 0.484, 6.874, 28.1, 6.4654, 5.0, 370.0, 17.6, 387.97, 4.61], [1, 9.91655, 0.0, 18.1, 0.0, 0.693, 5.852, 77.8, 1.5004, 24.0, 666.0, 20.2, 338.16, 29.97], [1, 2.924, 0.0, 19.58, 0.0, 0.605, 6.101, 93.0, 2.2834, 5.0, 403.0, 14.7, 240.16, 9.81], [1, 7.67202, 0.0, 18.1, 0.0, 0.693, 5.747, 98.9, 1.6334, 24.0, 666.0, 20.2, 393.1, 19.92], [1, 0.7258, 0.0, 8.14, 0.0, 0.538, 5.727, 69.5, 3.7965, 4.0, 307.0, 21.0, 390.95, 11.28], [1, 0.26838, 0.0, 9.69, 0.0, 0.585, 5.794, 70.6, 2.8927, 6.0, 391.0, 19.2, 396.9, 14.1], [1, 0.1415, 0.0, 6.91, 0.0, 0.448, 6.169, 6.6, 5.7209, 3.0, 233.0, 17.9, 383.37, 5.81], [1, 0.05515, 33.0, 2.18, 0.0, 0.472, 7.236, 41.1, 4.022, 7.0, 222.0, 18.4, 393.68, 6.93], [1, 0.04337, 21.0, 5.64, 0.0, 0.439, 6.115, 63.0, 6.8147, 4.0, 243.0, 16.8, 393.97, 9.43], [1, 13.3598, 0.0, 18.1, 0.0, 0.693, 5.887, 94.7, 1.7821, 24.0, 666.0, 20.2, 396.9, 16.35], [1, 2.37934, 0.0, 19.58, 0.0, 0.871, 6.13, 100.0, 1.4191, 5.0, 403.0, 14.7, 172.91, 27.8], [1, 0.28955, 0.0, 10.59, 0.0, 0.489, 5.412, 9.8, 3.5875, 4.0, 277.0, 18.6, 348.93, 29.55], [1, 0.04301, 80.0, 1.91, 0.0, 0.413, 5.663, 21.9, 10.5857, 4.0, 334.0, 22.0, 382.8, 8.05], [1, 0.09299, 0.0, 25.65, 0.0, 0.581, 5.961, 92.9, 2.0869, 2.0, 188.0, 19.1, 378.09, 17.93], [1, 0.01951, 17.5, 1.38, 0.0, 0.4161, 7.104, 59.5, 9.2229, 3.0, 216.0, 18.6, 393.24, 8.05], [1, 0.015380000000000001, 90.0, 3.75, 0.0, 0.394, 7.454, 34.2, 6.3361, 3.0, 244.0, 15.9, 386.34, 3.11], [1, 0.0566, 0.0, 3.41, 0.0, 0.489, 7.007, 86.3, 3.4217, 2.0, 270.0, 17.8, 396.9, 5.5], [1, 0.26938, 0.0, 9.9, 0.0, 0.544, 6.266, 82.8, 3.2628, 4.0, 304.0, 18.4, 393.39, 7.9], [1, 0.18337, 0.0, 27.74, 0.0, 0.609, 5.414, 98.3, 1.7554, 4.0, 711.0, 20.1, 344.05, 23.97], [1, 0.13158, 0.0, 10.01, 0.0, 0.547, 6.176, 72.5, 2.7301, 6.0, 432.0, 17.8, 393.3, 12.04], [1, 0.21038, 20.0, 3.33, 0.0, 0.4429, 6.812, 32.2, 4.1007, 5.0, 216.0, 14.9, 396.9, 4.85], [1, 0.10328, 25.0, 5.13, 0.0, 0.453, 5.927, 47.2, 6.932, 8.0, 284.0, 19.7, 396.9, 9.22], [1, 0.024980000000000002, 0.0, 1.89, 0.0, 0.518, 6.54, 59.7, 6.2669, 1.0, 422.0, 15.9, 389.96, 8.65], [1, 0.12082999999999999, 0.0, 2.89, 0.0, 0.445, 8.069, 76.0, 3.4952, 2.0, 276.0, 18.0, 396.9, 4.21], [1, 2.3309900000000003, 0.0, 19.58, 0.0, 0.871, 5.186, 93.8, 1.5296, 5.0, 403.0, 14.7, 356.99, 28.32], [1, 7.9924800000000005, 0.0, 18.1, 0.0, 0.7, 5.52, 100.0, 1.5331, 24.0, 666.0, 20.2, 396.9, 24.56], [1, 0.0456, 0.0, 13.89, 1.0, 0.55, 5.888, 56.0, 3.1121, 5.0, 276.0, 16.4, 392.8, 13.51], [1, 0.05083, 0.0, 5.19, 0.0, 0.515, 6.316, 38.1, 6.4584, 5.0, 224.0, 20.2, 389.71, 5.68], [1, 0.15445, 25.0, 5.13, 0.0, 0.453, 6.145, 29.2, 7.8148, 8.0, 284.0, 19.7, 390.68, 6.86], [1, 0.17004, 12.5, 7.87, 0.0, 0.524, 6.004, 85.9, 6.5921, 5.0, 311.0, 15.2, 386.71, 17.1], [1, 23.6482, 0.0, 18.1, 0.0, 0.671, 6.38, 96.2, 1.3861, 24.0, 666.0, 20.2, 396.9, 23.69], [1, 6.288069999999999, 0.0, 18.1, 0.0, 0.74, 6.341, 96.4, 2.072, 24.0, 666.0, 20.2, 318.01, 17.79], [1, 0.050230000000000004, 35.0, 6.06, 0.0, 0.4379, 5.706, 28.4, 6.6407, 1.0, 304.0, 16.9, 394.02, 12.43], [1, 10.8342, 0.0, 18.1, 0.0, 0.679, 6.782, 90.8, 1.8195, 24.0, 666.0, 20.2, 21.57, 25.79], [1, 0.07244, 60.0, 1.69, 0.0, 0.411, 5.884, 18.5, 10.7103, 4.0, 411.0, 18.3, 392.33, 7.79], [1, 0.65665, 20.0, 3.97, 0.0, 0.647, 6.842, 100.0, 2.0107, 5.0, 264.0, 13.0, 391.93, 6.9], [1, 4.812130000000001, 0.0, 18.1, 0.0, 0.713, 6.701, 90.0, 2.5975, 24.0, 666.0, 20.2, 255.23, 16.42], [1, 0.75026, 0.0, 8.14, 0.0, 0.538, 5.924, 94.1, 4.3996, 4.0, 307.0, 21.0, 394.33, 16.3], [1, 0.21977, 0.0, 6.91, 0.0, 0.448, 5.602, 62.0, 6.0877, 3.0, 233.0, 17.9, 396.9, 16.2], [1, 0.07165, 0.0, 25.65, 0.0, 0.581, 6.004, 84.1, 2.1974, 2.0, 188.0, 19.1, 377.67, 14.27], [1, 0.22876, 0.0, 8.56, 0.0, 0.52, 6.405, 85.4, 2.7147, 5.0, 384.0, 20.9, 70.8, 10.63], [1, 0.04203, 28.0, 15.04, 0.0, 0.464, 6.442, 53.6, 3.6659, 4.0, 270.0, 18.2, 395.01, 8.16], [1, 0.02731, 0.0, 7.07, 0.0, 0.469, 6.421, 78.9, 4.9671, 2.0, 242.0, 17.8, 396.9, 9.14], [1, 0.06162, 0.0, 4.39, 0.0, 0.442, 5.898, 52.3, 8.0136, 3.0, 352.0, 18.8, 364.61, 12.67], [1, 9.33889, 0.0, 18.1, 0.0, 0.679, 6.38, 95.6, 1.9682, 24.0, 666.0, 20.2, 60.72, 24.08], [1, 0.04741, 0.0, 11.93, 0.0, 0.573, 6.03, 80.8, 2.505, 1.0, 273.0, 21.0, 396.9, 7.88], [1, 0.06129, 20.0, 3.33, 1.0, 0.4429, 7.645, 49.7, 5.2119, 5.0, 216.0, 14.9, 377.07, 3.01], [1, 0.31827, 0.0, 9.9, 0.0, 0.544, 5.914, 83.2, 3.9986, 4.0, 304.0, 18.4, 390.7, 18.33], [1, 0.1396, 0.0, 8.56, 0.0, 0.52, 6.167, 90.0, 2.421, 5.0, 384.0, 20.9, 392.69, 12.33], [1, 0.03466, 35.0, 6.06, 0.0, 0.4379, 6.031, 23.3, 6.6407, 1.0, 304.0, 16.9, 362.25, 7.83], [1, 0.04981, 21.0, 5.64, 0.0, 0.439, 5.998, 21.4, 6.8147, 4.0, 243.0, 16.8, 396.9, 8.43], [1, 0.84054, 0.0, 8.14, 0.0, 0.538, 5.599, 85.7, 4.4546, 4.0, 307.0, 21.0, 303.42, 16.51], [1, 2.3139, 0.0, 19.58, 0.0, 0.605, 5.88, 97.3, 2.3887, 5.0, 403.0, 14.7, 348.13, 12.03], [1, 7.52601, 0.0, 18.1, 0.0, 0.713, 6.417, 98.3, 2.185, 24.0, 666.0, 20.2, 304.21, 19.31], [1, 5.7081800000000005, 0.0, 18.1, 0.0, 0.532, 6.75, 74.9, 3.3317, 24.0, 666.0, 20.2, 393.07, 7.74], [1, 6.71772, 0.0, 18.1, 0.0, 0.713, 6.749, 92.6, 2.3236, 24.0, 666.0, 20.2, 0.32, 17.44], [1, 0.1403, 22.0, 5.86, 0.0, 0.431, 6.487, 13.0, 7.3967, 7.0, 330.0, 19.1, 396.28, 5.9], [1, 0.12329000000000001, 0.0, 10.01, 0.0, 0.547, 5.913, 92.9, 2.3534, 6.0, 432.0, 17.8, 394.95, 16.21], [1, 6.53876, 0.0, 18.1, 1.0, 0.631, 7.016, 97.5, 1.2024, 24.0, 666.0, 20.2, 392.05, 2.96], [1, 0.52693, 0.0, 6.2, 0.0, 0.504, 8.725, 83.0, 2.8944, 8.0, 307.0, 17.4, 382.0, 4.63], [1, 0.11132, 0.0, 27.74, 0.0, 0.609, 5.983, 83.5, 2.1099, 4.0, 711.0, 20.1, 396.9, 13.35], [1, 0.03113, 0.0, 4.39, 0.0, 0.442, 6.014, 48.5, 8.0136, 3.0, 352.0, 18.8, 385.64, 10.53], [1, 0.7842, 0.0, 8.14, 0.0, 0.538, 5.99, 81.7, 4.2579, 4.0, 307.0, 21.0, 386.75, 14.67], [1, 9.329089999999999, 0.0, 18.1, 0.0, 0.713, 6.185, 98.7, 2.2616, 24.0, 666.0, 20.2, 396.9, 18.13], [1, 0.03961, 0.0, 5.19, 0.0, 0.515, 6.037, 34.5, 5.9853, 5.0, 224.0, 20.2, 396.9, 8.01], [1, 0.19802, 0.0, 10.59, 0.0, 0.489, 6.182, 42.4, 3.9454, 4.0, 277.0, 18.6, 393.63, 9.47], [1, 3.4742800000000003, 0.0, 18.1, 1.0, 0.718, 8.78, 82.9, 1.9047, 24.0, 666.0, 20.2, 354.55, 5.29], [1, 11.0874, 0.0, 18.1, 0.0, 0.718, 6.411, 100.0, 1.8589, 24.0, 666.0, 20.2, 318.75, 15.02], [1, 0.17142000000000002, 0.0, 6.91, 0.0, 0.448, 5.682, 33.8, 5.1004, 3.0, 233.0, 17.9, 396.9, 10.21], [1, 0.01096, 55.0, 2.25, 0.0, 0.389, 6.453, 31.9, 7.3073, 1.0, 300.0, 15.3, 394.72, 8.23], [1, 0.37578, 0.0, 10.59, 1.0, 0.489, 5.404, 88.6, 3.665, 4.0, 277.0, 18.6, 395.24, 23.98], [1, 0.12269000000000001, 0.0, 6.91, 0.0, 0.448, 6.069, 40.0, 5.7209, 3.0, 233.0, 17.9, 389.39, 9.55], [1, 0.15936, 0.0, 6.91, 0.0, 0.448, 6.211, 6.5, 5.7209, 3.0, 233.0, 17.9, 394.46, 7.44], [1, 0.09266, 34.0, 6.09, 0.0, 0.433, 6.495, 18.4, 5.4917, 7.0, 329.0, 16.1, 383.61, 8.67], [1, 1.13081, 0.0, 8.14, 0.0, 0.538, 5.713, 94.1, 4.233, 4.0, 307.0, 21.0, 360.17, 22.6], [1, 13.0751, 0.0, 18.1, 0.0, 0.58, 5.713, 56.7, 2.8237, 24.0, 666.0, 20.2, 396.9, 14.76], [1, 0.05789, 12.5, 6.07, 0.0, 0.409, 5.878, 21.4, 6.498, 4.0, 345.0, 18.9, 396.21, 8.1], [1, 0.13642, 0.0, 10.59, 0.0, 0.489, 5.891, 22.3, 3.9454, 4.0, 277.0, 18.6, 396.9, 10.87], [1, 0.16211, 20.0, 6.96, 0.0, 0.464, 6.24, 16.3, 4.429, 3.0, 223.0, 18.6, 396.9, 6.59], [1, 9.2323, 0.0, 18.1, 0.0, 0.631, 6.216, 100.0, 1.1691, 24.0, 666.0, 20.2, 366.15, 9.53], [1, 41.5292, 0.0, 18.1, 0.0, 0.693, 5.531, 85.4, 1.6074, 24.0, 666.0, 20.2, 329.46, 27.38], [1, 15.8744, 0.0, 18.1, 0.0, 0.671, 6.545, 99.1, 1.5192, 24.0, 666.0, 20.2, 396.9, 21.08], [1, 0.03427, 0.0, 5.19, 0.0, 0.515, 5.869, 46.3, 5.2311, 5.0, 224.0, 20.2, 396.9, 9.8], [1, 0.04666, 80.0, 1.52, 0.0, 0.404, 7.107, 36.6, 7.309, 2.0, 329.0, 12.6, 354.31, 8.61], [1, 1.6286399999999999, 0.0, 21.89, 0.0, 0.624, 5.019, 100.0, 1.4394, 4.0, 437.0, 21.2, 396.9, 34.41], [1, 22.0511, 0.0, 18.1, 0.0, 0.74, 5.818, 92.4, 1.8662, 24.0, 666.0, 20.2, 391.45, 22.11], [1, 5.29305, 0.0, 18.1, 0.0, 0.7, 6.051, 82.5, 2.1678, 24.0, 666.0, 20.2, 378.38, 18.76], [1, 0.9761700000000001, 0.0, 21.89, 0.0, 0.624, 5.757, 98.4, 2.346, 4.0, 437.0, 21.2, 262.76, 17.31], [1, 67.9208, 0.0, 18.1, 0.0, 0.693, 5.683, 100.0, 1.4254, 24.0, 666.0, 20.2, 384.97, 22.98], [1, 0.015009999999999999, 90.0, 1.21, 1.0, 0.401, 7.923, 24.8, 5.885, 1.0, 198.0, 13.6, 395.52, 3.16], [1, 0.054970000000000005, 0.0, 5.19, 0.0, 0.515, 5.985, 45.4, 4.8122, 5.0, 224.0, 20.2, 396.9, 9.74], [1, 0.04684, 0.0, 3.41, 0.0, 0.489, 6.417, 66.1, 3.0923, 2.0, 270.0, 17.8, 392.18, 8.81], [1, 4.34879, 0.0, 18.1, 0.0, 0.58, 6.167, 84.0, 3.0334, 24.0, 666.0, 20.2, 396.9, 16.29], [1, 14.4208, 0.0, 18.1, 0.0, 0.74, 6.461, 93.3, 2.0026, 24.0, 666.0, 20.2, 27.49, 18.05], [1, 0.06642, 0.0, 4.05, 0.0, 0.51, 6.86, 74.4, 2.9153, 5.0, 296.0, 16.6, 391.27, 6.92], [1, 2.14918, 0.0, 19.58, 0.0, 0.871, 5.709, 98.5, 1.6232, 5.0, 403.0, 14.7, 261.95, 15.79], [1, 0.1676, 0.0, 7.38, 0.0, 0.493, 6.426, 52.3, 4.5404, 5.0, 287.0, 19.6, 396.9, 7.2], [1, 0.36894, 22.0, 5.86, 0.0, 0.431, 8.259, 8.4, 8.9067, 7.0, 330.0, 19.1, 396.9, 3.54], [1, 0.053020000000000005, 0.0, 3.41, 0.0, 0.489, 7.079, 63.1, 3.4145, 2.0, 270.0, 17.8, 396.06, 5.7], [1, 0.15037999999999999, 0.0, 25.65, 0.0, 0.581, 5.856, 97.0, 1.9444, 2.0, 188.0, 19.1, 370.31, 25.41], [1, 1.34284, 0.0, 19.58, 0.0, 0.605, 6.066, 100.0, 1.7573, 5.0, 403.0, 14.7, 353.89, 6.43], [1, 0.08707000000000001, 0.0, 12.83, 0.0, 0.437, 6.14, 45.8, 4.0905, 5.0, 398.0, 18.7, 386.96, 10.27], [1, 0.38735, 0.0, 25.65, 0.0, 0.581, 5.613, 95.6, 1.7572, 2.0, 188.0, 19.1, 359.29, 27.26], [1, 0.46296000000000004, 0.0, 6.2, 0.0, 0.504, 7.412, 76.9, 3.6715, 8.0, 307.0, 17.4, 376.14, 5.25], [1, 7.40389, 0.0, 18.1, 0.0, 0.597, 5.617, 97.9, 1.4547, 24.0, 666.0, 20.2, 314.64, 26.4], [1, 1.4250200000000002, 0.0, 19.58, 0.0, 0.871, 6.51, 100.0, 1.7659, 5.0, 403.0, 14.7, 364.31, 7.39], [1, 20.7162, 0.0, 18.1, 0.0, 0.659, 4.138, 100.0, 1.1781, 24.0, 666.0, 20.2, 370.22, 23.34], [1, 0.10008, 0.0, 2.46, 0.0, 0.488, 6.563, 95.6, 2.847, 3.0, 193.0, 17.8, 396.9, 5.68], [1, 8.05579, 0.0, 18.1, 0.0, 0.584, 5.427, 95.4, 2.4298, 24.0, 666.0, 20.2, 352.58, 18.14], [1, 0.02009, 95.0, 2.68, 0.0, 0.4161, 8.034, 31.9, 5.118, 4.0, 224.0, 14.7, 390.55, 2.88], [1, 0.030410000000000003, 0.0, 5.19, 0.0, 0.515, 5.895, 59.6, 5.615, 5.0, 224.0, 20.2, 394.81, 10.56], [1, 0.15086, 0.0, 27.74, 0.0, 0.609, 5.454, 92.7, 1.8209, 4.0, 711.0, 20.1, 395.09, 18.06], [1, 0.13058, 0.0, 10.01, 0.0, 0.547, 5.872, 73.1, 2.4775, 6.0, 432.0, 17.8, 338.63, 15.37], [1, 0.06617, 0.0, 3.24, 0.0, 0.46, 5.868, 25.8, 5.2146, 4.0, 430.0, 16.9, 382.44, 9.97], [1, 14.2362, 0.0, 18.1, 0.0, 0.693, 6.343, 100.0, 1.5741, 24.0, 666.0, 20.2, 396.9, 20.32], [1, 0.08308, 0.0, 2.46, 0.0, 0.488, 5.604, 89.8, 2.9879, 3.0, 193.0, 17.8, 391.0, 13.98], [1, 0.35233000000000003, 0.0, 21.89, 0.0, 0.624, 6.454, 98.4, 1.8498, 4.0, 437.0, 21.2, 394.08, 14.59], [1, 0.13587, 0.0, 10.59, 1.0, 0.489, 6.064, 59.1, 4.2392, 4.0, 277.0, 18.6, 381.32, 14.66], [1, 0.5201399999999999, 20.0, 3.97, 0.0, 0.647, 8.398, 91.5, 2.2885, 5.0, 264.0, 13.0, 386.86, 5.91], [1, 0.061270000000000005, 40.0, 6.41, 1.0, 0.447, 6.826, 27.6, 4.8628, 4.0, 254.0, 17.6, 393.45, 4.16], [1, 37.6619, 0.0, 18.1, 0.0, 0.679, 6.202, 78.7, 1.8629, 24.0, 666.0, 20.2, 18.82, 14.52], [1, 0.05602000000000001, 0.0, 2.46, 0.0, 0.488, 7.831, 53.6, 3.1992, 3.0, 193.0, 17.8, 392.63, 4.45], [1, 0.06151, 0.0, 5.19, 0.0, 0.515, 5.968, 58.5, 4.8122, 5.0, 224.0, 20.2, 396.9, 9.29], [1, 0.03705, 20.0, 3.33, 0.0, 0.4429, 6.968, 37.2, 5.2447, 5.0, 216.0, 14.9, 392.23, 4.59], [1, 0.18159, 0.0, 7.38, 0.0, 0.493, 6.376, 54.3, 4.5404, 5.0, 287.0, 19.6, 396.9, 6.87], [1, 0.15875999999999998, 0.0, 10.81, 0.0, 0.413, 5.961, 17.5, 5.2873, 4.0, 305.0, 19.2, 376.94, 9.88], [1, 2.81838, 0.0, 18.1, 0.0, 0.532, 5.762, 40.3, 4.0983, 24.0, 666.0, 20.2, 392.92, 10.42], [1, 0.10959, 0.0, 11.93, 0.0, 0.573, 6.794, 89.3, 2.3889, 1.0, 273.0, 21.0, 393.45, 6.48], [1, 0.03551, 25.0, 4.86, 0.0, 0.426, 6.167, 46.7, 5.4007, 4.0, 281.0, 19.0, 390.64, 7.51], [1, 5.73116, 0.0, 18.1, 0.0, 0.532, 7.061, 77.0, 3.4106, 24.0, 666.0, 20.2, 395.28, 7.01], [1, 10.6718, 0.0, 18.1, 0.0, 0.74, 6.459, 94.8, 1.9879, 24.0, 666.0, 20.2, 43.06, 23.98], [1, 0.02899, 40.0, 1.25, 0.0, 0.429, 6.939, 34.5, 8.7921, 1.0, 335.0, 19.7, 389.85, 5.89], [1, 18.811, 0.0, 18.1, 0.0, 0.597, 4.628, 100.0, 1.5539, 24.0, 666.0, 20.2, 28.79, 34.37], [1, 0.80271, 0.0, 8.14, 0.0, 0.538, 5.456, 36.6, 3.7965, 4.0, 307.0, 21.0, 288.99, 11.69], [1, 0.04417, 70.0, 2.24, 0.0, 0.4, 6.871, 47.4, 7.8278, 5.0, 358.0, 14.8, 390.86, 6.07], [1, 73.5341, 0.0, 18.1, 0.0, 0.679, 5.957, 100.0, 1.8026, 24.0, 666.0, 20.2, 16.45, 20.62], [1, 0.47547, 0.0, 9.9, 0.0, 0.544, 6.113, 58.8, 4.0019, 4.0, 304.0, 18.4, 396.23, 12.73], [1, 0.08244, 30.0, 4.93, 0.0, 0.428, 6.481, 18.5, 6.1899, 6.0, 300.0, 16.6, 379.41, 6.36], [1, 0.050589999999999996, 0.0, 4.49, 0.0, 0.449, 6.389, 48.0, 4.7794, 3.0, 247.0, 18.5, 396.9, 9.62], [1, 1.6128200000000001, 0.0, 8.14, 0.0, 0.538, 6.096, 96.9, 3.7598, 4.0, 307.0, 21.0, 248.31, 20.34], [1, 1.51902, 0.0, 19.58, 1.0, 0.605, 8.375, 93.9, 2.162, 5.0, 403.0, 14.7, 388.45, 3.32], [1, 0.14932, 25.0, 5.13, 0.0, 0.453, 5.741, 66.2, 7.2254, 8.0, 284.0, 19.7, 395.11, 13.15], [1, 15.0234, 0.0, 18.1, 0.0, 0.614, 5.304, 97.3, 2.1007, 24.0, 666.0, 20.2, 349.48, 24.91], [1, 0.62739, 0.0, 8.14, 0.0, 0.538, 5.834, 56.5, 4.4986, 4.0, 307.0, 21.0, 395.62, 8.47], [1, 1.00245, 0.0, 8.14, 0.0, 0.538, 6.674, 87.3, 4.239, 4.0, 307.0, 21.0, 380.23, 11.98], [1, 0.23911999999999997, 0.0, 9.69, 0.0, 0.585, 6.019, 65.3, 2.4091, 6.0, 391.0, 19.2, 396.9, 12.92], [1, 0.32264, 0.0, 21.89, 0.0, 0.624, 5.942, 93.5, 1.9669, 4.0, 437.0, 21.2, 378.25, 16.9], [1, 0.12757000000000002, 30.0, 4.93, 0.0, 0.428, 6.393, 7.8, 7.0355, 6.0, 300.0, 16.6, 374.71, 5.19], [1, 0.12744, 0.0, 6.91, 0.0, 0.448, 6.77, 2.9, 5.7209, 3.0, 233.0, 17.9, 385.41, 4.84], [1, 3.5350099999999998, 0.0, 19.58, 1.0, 0.871, 6.152, 82.6, 1.7455, 5.0, 403.0, 14.7, 88.01, 15.02], [1, 4.22239, 0.0, 18.1, 1.0, 0.77, 5.803, 89.0, 1.9047, 24.0, 666.0, 20.2, 353.04, 14.64], [1, 0.05646, 0.0, 12.83, 0.0, 0.437, 6.232, 53.7, 5.0141, 5.0, 398.0, 18.7, 386.4, 12.34], [1, 7.05042, 0.0, 18.1, 0.0, 0.614, 6.103, 85.1, 2.0218, 24.0, 666.0, 20.2, 2.52, 23.29], [1, 0.09103, 0.0, 2.46, 0.0, 0.488, 7.155, 92.2, 2.7006, 3.0, 193.0, 17.8, 394.12, 4.82], [1, 5.87205, 0.0, 18.1, 0.0, 0.693, 6.405, 96.0, 1.6768, 24.0, 666.0, 20.2, 396.9, 19.37], [1, 25.0461, 0.0, 18.1, 0.0, 0.693, 5.987, 100.0, 1.5888, 24.0, 666.0, 20.2, 396.9, 26.77], [1, 0.08187, 0.0, 2.89, 0.0, 0.445, 7.82, 36.9, 3.4952, 2.0, 276.0, 18.0, 393.53, 3.57], [1, 0.08829, 12.5, 7.87, 0.0, 0.524, 6.012, 66.6, 5.5605, 5.0, 311.0, 15.2, 395.6, 12.43], [1, 16.8118, 0.0, 18.1, 0.0, 0.7, 5.277, 98.1, 1.4261, 24.0, 666.0, 20.2, 396.9, 30.81], [1, 0.09178, 0.0, 4.05, 0.0, 0.51, 6.416, 84.1, 2.6463, 5.0, 296.0, 16.6, 395.5, 9.04], [1, 0.06076, 0.0, 11.93, 0.0, 0.573, 6.976, 91.0, 2.1675, 1.0, 273.0, 21.0, 396.9, 5.64], [1, 0.14103, 0.0, 13.92, 0.0, 0.437, 5.79, 58.0, 6.32, 4.0, 289.0, 16.0, 396.9, 15.84], [1, 0.14866, 0.0, 8.56, 0.0, 0.52, 6.727, 79.9, 2.7778, 5.0, 384.0, 20.9, 394.76, 9.42], [1, 0.07977999999999999, 40.0, 6.41, 0.0, 0.447, 6.482, 32.1, 4.1403, 4.0, 254.0, 17.6, 396.9, 7.19], [1, 7.83932, 0.0, 18.1, 0.0, 0.655, 6.209, 65.4, 2.9634, 24.0, 666.0, 20.2, 396.9, 13.22], [1, 0.02543, 55.0, 3.78, 0.0, 0.484, 6.696, 56.4, 5.7321, 5.0, 370.0, 17.6, 396.9, 7.18], [1, 0.44178, 0.0, 6.2, 0.0, 0.504, 6.552, 21.4, 3.3751, 8.0, 307.0, 17.4, 380.34, 3.76], [1, 0.013009999999999999, 35.0, 1.52, 0.0, 0.442, 7.241, 49.3, 7.0379, 1.0, 284.0, 15.5, 394.74, 5.49], [1, 0.06724, 0.0, 3.24, 0.0, 0.46, 6.333, 17.2, 5.2146, 4.0, 430.0, 16.9, 375.21, 7.34], [1, 0.13554000000000002, 12.5, 6.07, 0.0, 0.409, 5.594, 36.8, 6.498, 4.0, 345.0, 18.9, 396.9, 13.09], [1, 0.009059999999999999, 90.0, 2.97, 0.0, 0.4, 7.088, 20.8, 7.3073, 1.0, 285.0, 15.3, 394.72, 7.85], [1, 1.27346, 0.0, 19.58, 1.0, 0.605, 6.25, 92.6, 1.7984, 5.0, 403.0, 14.7, 338.92, 5.5], [1, 0.06905, 0.0, 2.18, 0.0, 0.458, 7.147, 54.2, 6.0622, 3.0, 222.0, 18.7, 396.9, 5.33], [1, 9.96654, 0.0, 18.1, 0.0, 0.74, 6.485, 100.0, 1.9784, 24.0, 666.0, 20.2, 386.73, 18.85], [1, 14.0507, 0.0, 18.1, 0.0, 0.597, 6.657, 100.0, 1.5275, 24.0, 666.0, 20.2, 35.05, 21.22], [1, 0.11432, 0.0, 8.56, 0.0, 0.52, 6.781, 71.3, 2.8561, 5.0, 384.0, 20.9, 395.58, 7.67], [1, 0.59005, 0.0, 21.89, 0.0, 0.624, 6.372, 97.9, 2.3274, 4.0, 437.0, 21.2, 385.76, 11.12], [1, 0.0686, 0.0, 2.89, 0.0, 0.445, 7.416, 62.5, 3.4952, 2.0, 276.0, 18.0, 396.9, 6.19], [1, 0.03615, 80.0, 4.95, 0.0, 0.411, 6.63, 23.4, 5.1167, 4.0, 245.0, 19.2, 396.9, 4.7], [1, 0.17505, 0.0, 5.96, 0.0, 0.499, 5.966, 30.2, 3.8473, 5.0, 279.0, 19.2, 393.43, 10.13], [1, 6.65492, 0.0, 18.1, 0.0, 0.713, 6.317, 83.0, 2.7344, 24.0, 666.0, 20.2, 396.9, 13.99], [1, 0.13117, 0.0, 8.56, 0.0, 0.52, 6.127, 85.2, 2.1224, 5.0, 384.0, 20.9, 387.69, 14.09], [1, 0.06466000000000001, 70.0, 2.24, 0.0, 0.4, 6.345, 20.1, 7.8278, 5.0, 358.0, 14.8, 368.24, 4.97]]\n",
      "------------------\n",
      "------------------\n",
      "Closed Form Solution RMS: 4.8925096677990165\n",
      "[[ 1.         -0.30636564 -0.48182192 ...,  1.1843845  -0.61270683\n",
      "   0.64065772]\n",
      " [ 1.         -0.4077453   0.7479879  ..., -0.12072239  0.42568394\n",
      "  -0.89726257]\n",
      " [ 1.         -0.27707773 -0.48182192 ..., -1.752106    0.04588342\n",
      "  -1.12232408]\n",
      " ..., \n",
      " [ 1.          0.31689798 -0.48182192 ...,  0.81149682  0.43226407\n",
      "   0.18358837]\n",
      " [ 1.         -0.39654456 -0.48182192 ...,  1.13777354  0.32594301\n",
      "   0.19748105]\n",
      " [ 1.         -0.40381815  2.59270262 ..., -1.70549504  0.10141049\n",
      "  -1.06953188]]\n",
      "Closed FormSol With Ridge RMS: 4.882792894560511\n"
     ]
    }
   ],
   "source": [
    "#normalize the data set ny (x-u)/s where s is max-min\n",
    "def normalizePhi1(unNormalizedPhi,testdata):\n",
    "    mergedPhi=unNormalizedPhi+testdata;\n",
    "    phi=np.array(mergedPhi);\n",
    "    npPhi=np.array(unNormalizedPhi);\n",
    "    npTestdata=np.array(testdata);\n",
    "    print(\"Normalizing Phi111...\");  \n",
    "    std=phi.std(0);\n",
    "    mean=phi.mean(0);    \n",
    "    std[0]=1;\n",
    "    mean[0]=0;\n",
    "    phi_normalize=(npPhi-mean)/std;  \n",
    "    testdata_norm=(npTestdata-mean)/std;  \n",
    "    print(\"Normalization done.\");\n",
    "    return [phi_normalize,testdata_norm];\n",
    "    pass;\n",
    "\n",
    "def mainClosedFormSol(dataset):\n",
    "\n",
    "    trainDatasetPhi=dataset[0];\n",
    "    trainDatasetY=dataset[1];\n",
    "    validateDatasetPhi=dataset[2];\n",
    "    validateDatasetY=dataset[3];\n",
    "    testDS=dataset[4];\n",
    "    #--------------------[Closed Form Sol without Regularlization]--------------------------------\n",
    "    #Find w*\n",
    "    wStar=trainUsingClosedFormEquation(trainDatasetPhi,trainDatasetY);\n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(validateDatasetPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(validateDatasetY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(testDS,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Closed Form Solution RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    pass;\n",
    "\n",
    "\n",
    "def mainRidgeClosedFormSol(dataset):\n",
    "    \n",
    "    trainDatasetPhi=dataset[0];\n",
    "    trainDatasetY=dataset[1];\n",
    "    validateDatasetPhi=dataset[2];\n",
    "    validateDatasetY=dataset[3];\n",
    "    testDS=dataset[4];\n",
    "    #--------------------[Closed Form Sol without Regularlization]--------------------------------\n",
    "    #Find w*\n",
    "    wStar=trainUsingClosedFormRidgeEq(trainDatasetPhi,trainDatasetY);\n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(validateDatasetPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(validateDatasetY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(testDS_norm,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Closed FormSol With Ridge RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    pass;\n",
    "\n",
    "def mainGradientDesent(dataset):\n",
    "    trainDatasetPhi=dataset[0];\n",
    "    trainDatasetY=dataset[1];\n",
    "    validateDatasetPhi=dataset[2];\n",
    "    validateDatasetY=dataset[3];\n",
    "    testDS=dataset[4];\n",
    "    #--------------------[Gradient decent without Regularlization]--------------------------------\n",
    "    wStar=gardientDescentWithRidge(trainDatasetPhi,trainDatasetY);\n",
    "    #wStar=gardientDescentWithPnom(trainDatasetPhi,trainDatasetY,(4/3));\n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(validateDatasetPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(validateDatasetY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(testDS_norm,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Gradient Desent ||Norm||=2 RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "#--settings--\n",
    "np.set_printoptions(suppress=True)\n",
    "#---init---\n",
    "dir=\"\"\n",
    "trainFile=dir+\"train.csv\";\n",
    "testFile=dir+\"test.csv\";\n",
    "trainDSSizePercentage=0.7; # x*100 percentage. 1-x data set will be used for validating\n",
    "\n",
    "print(\"Fetching Trained Dataset from file...\");\n",
    "dataset=readTrainData(trainFile);\n",
    "testDS=readTestData(testFile);\n",
    "phiSet=dataset[0];\n",
    "ySet=dataset[1];\n",
    "\n",
    "phiSet_norm=normalizePhi(phiSet);\n",
    "testDS_norm=normalizePhi(testDS);\n",
    "dataset=spitTrainDataset(phiSet,ySet);\n",
    "tds=spitTrainDataset(phiSet,ySet);\n",
    "tds_norm=spitTrainDataset(phiSet_norm,ySet);\n",
    "\n",
    "\n",
    "print(\"Fetching of data Completed.\");\n",
    "\n",
    "#train set\n",
    "trainDatasetPhi=tds[0];\n",
    "trainDatasetY=tds[1];\n",
    "validateDatasetPhi=tds[2];\n",
    "validateDatasetY=tds[3];\n",
    "\n",
    "trainDatasetPhi_norm=tds_norm[0];\n",
    "trainDatasetY_norm=tds_norm[1];\n",
    "validateDatasetPhi_norm=tds_norm[2];\n",
    "validateDatasetY_norm=tds_norm[3];\n",
    "print(\"Train Size:\"+str(len(trainDatasetPhi)));\n",
    "print(\"Validate Size:\"+str(len(validateDatasetPhi)));\n",
    "\n",
    "ds=[trainDatasetPhi,trainDatasetY,validateDatasetPhi,validateDatasetY,testDS];\n",
    "ds_norm=[trainDatasetPhi_norm,trainDatasetY,validateDatasetPhi_norm,validateDatasetY,testDS];\n",
    "mainClosedFormSol(ds);\n",
    "mainRidgeClosedFormSol(ds_norm);\n",
    "#mainGradientDesent(ds_norm);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
