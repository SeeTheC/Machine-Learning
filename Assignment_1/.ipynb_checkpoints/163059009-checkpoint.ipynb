{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "from numpy.linalg import inv;\n",
    "from numpy.linalg import det;\n",
    "import math;\n",
    "\n",
    "# Will read the file and convert it into two dataset one train data other validate data\n",
    "def readTrainData(fileName):\n",
    "    row_index=0;\n",
    "    phi=list();\n",
    "    y=list();\n",
    "    with open(fileName) as f:\n",
    "        for line in f:\n",
    "            if row_index >0:\n",
    "                phi_i=list((float(n) for n in line.split('\\n')[0].split(\",\") ));\n",
    "                if(addW0Col):\n",
    "                    phi_i[0]=1;\n",
    "                else:# removing id col.\n",
    "                    phi_i.pop();\n",
    "                # last row is value of yi                \n",
    "                y_i=phi_i.pop(len(phi_i)-1); \n",
    "                phi.append(phi_i);             \n",
    "                y.append(y_i);\n",
    "            row_index+=1;\n",
    "    return [phi,y];\n",
    "#End-readTrainData\n",
    "\n",
    "# Will read the file and convert it into dataset for Testing the Model\n",
    "def readTestData(fileName):\n",
    "    row_index=0;\n",
    "    phi=list();\n",
    "    y=list();\n",
    "    with open(fileName) as f:\n",
    "        for line in f:\n",
    "            if row_index >0:                \n",
    "                phi_i=list((float(n) for n in line.split('\\n')[0].split(\",\") ));\n",
    "                if(addW0Col):\n",
    "                    phi_i[0]=1;\n",
    "                else:# removing id col.\n",
    "                    phi_i.pop();                \n",
    "                phi.append(phi_i);                             \n",
    "            row_index+=1;\n",
    "    m=len(phi);    \n",
    "    return phi;\n",
    "#End-readTrainData\n",
    "\n",
    "\n",
    "\n",
    "#write-output\n",
    "def writeTestData(ystar):\n",
    "    fo = open(\"output.csv\", \"w\");    \n",
    "    fo.write(\"ID,MEDV\\n\");\n",
    "    m=len(ystar);\n",
    "    for i in range(m):\n",
    "        fo.write(str(i)+\",\"+str(ystar[i])+\"\\n\");\n",
    "    fo.close();\n",
    "    pass;\n",
    "\n",
    "# Return det of matrix\n",
    "def getDet(A):\n",
    "    d=det(A);\n",
    "    if(d<10**-10):\n",
    "        return 0;\n",
    "    return d;\n",
    "\n",
    "\n",
    "#Return RMS: root mean square error\n",
    "def getRMS(y,yStar):\n",
    "    m=len(y);\n",
    "    sigma=0;\n",
    "    for i in range(m):\n",
    "        delta=(y[i]-yStar[i]);\n",
    "        delta=delta*delta;\n",
    "        sigma=sigma+delta;\n",
    "    meanSq=sigma/m;   \n",
    "    rms=math.sqrt(meanSq);\n",
    "    return rms;\n",
    "    pass;\n",
    "\n",
    "#For ploting graph of RMS VS Iteration\n",
    "def plotGraph(x,y):\n",
    "    import matplotlib.pyplot as plt;\n",
    "    plt.plot(x,y)\n",
    "    plt.ylabel('rms')\n",
    "    plt.xlabel('iteration');\n",
    "    plt.show();\n",
    "    pass;\n",
    "\n",
    "#Record readings for gradient descent\n",
    "def writeReadingInFile(filename,alpha,lam,iteration,rms,p):\n",
    "    import os.path;\n",
    "    import datetime;\n",
    "    import time;\n",
    "    ts = datetime.datetime.fromtimestamp(time.time()).strftime('%d-%m-%Y %H:%M:%S')\n",
    "    if(os.path.exists(filename)==False):\n",
    "        fo = open(filename, \"w\"); \n",
    "        fo.write(\"iteration,norm,alpha,lam,rms,timestamp\\n\");\n",
    "        fo.write(str(iteration)+\",\"+str(p)+\",\"+str(alpha)+\",\"+str(lam)+\",\"+str(rms)+\",\"+str(ts)+\"\\n\");\n",
    "    else:\n",
    "        fo = open(filename, \"a\"); \n",
    "        fo.write(str(iteration)+\",\"+str(p)+\",\"+str(alpha)+\",\"+str(lam)+\",\"+str(rms)+\",\"+str(ts)+\"\\n\");\n",
    "    fo.close();                    \n",
    "    pass;\n",
    "\n",
    "\n",
    "#normalize the data set ny (x-u)/s where s is max-min\n",
    "def normalizePhi(unNormalizedPhi):    \n",
    "    phi=np.array(unNormalizedPhi);\n",
    "    print(\"Normalizing Phi...\");  \n",
    "    std=phi.std(0);\n",
    "    mean=phi.mean(0); \n",
    "    if(addW0Col):#making first col. mean as 0              \n",
    "        std[0]=1;\n",
    "        mean[0]=0;\n",
    "    phi_normalize=(phi-mean)/std;    \n",
    "    print(\"Normalization done.\");\n",
    "    return phi_normalize;\n",
    "    pass;\n",
    "\n",
    "#pridict of y* given w* QW=y*\n",
    "def pridict(dataset,weight):\n",
    "    phi=np.array(dataset);\n",
    "    w=np.array(weight);\n",
    "    ystar=np.dot(phi,w);\n",
    "    return ystar;\n",
    "    pass;\n",
    "\n",
    "# Finding w*=(QTQ)^-1QTY\n",
    "def trainUsingClosedFormEquation(dataset,output):\n",
    "    m=len(dataset);\n",
    "    n=len(dataset[0]);\n",
    "    phi=np.array(dataset);\n",
    "    y=np.array(output);\n",
    "    phiT=np.transpose(phi);\n",
    "    #(QTQ)    \n",
    "    phiT_phi=np.dot(phiT,phi); \n",
    "    d=getDet(phiT_phi)\n",
    "    if(True or d>0):\n",
    "        #(QTQ)^-1\n",
    "        phiT_phi_inv=inv(phiT_phi);\n",
    "        #(QTQ)^-1QT\n",
    "        phiT_phi_inv_phiT=np.dot(phiT_phi_inv,phiT);  \n",
    "        #(QTQ)^-1QT*Y\n",
    "        w=np.dot(phiT_phi_inv_phiT,y);      \n",
    "        return w;   \n",
    "    else:\n",
    "        print(\"Error:Phi is NOT full column rank.\");\n",
    "        return None;\n",
    "    pass;\n",
    "\n",
    "def numpiTestFun():\n",
    "    A2= np.matrix([[4,6],[2,8]])        \n",
    "    A3= np.matrix([[1,2,3],[4,5,7],[7,8,9]])\n",
    "    A=A2;\n",
    "    print(A);\n",
    "    print(np.power(A,0.5));\n",
    "    print(A);\n",
    "    print(\"Det(A):\"+str(getDet(A)));\n",
    "    B= np.transpose(A);\n",
    "    C=inv(A);\n",
    "    #print(C);\n",
    "    print(np.dot(A,C));\n",
    "    print(A.std(0));\n",
    "    print(A.mean(0));\n",
    "    print(normalizePhi(A));\n",
    "    norm=(A-A.mean(0))/A.std(0);    \n",
    "    print(norm);    \n",
    "    print();\n",
    "    pass;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12 156]\n"
     ]
    }
   ],
   "source": [
    "# GD: Least Sq. Without Regularlization\n",
    "def gardientDescentErrorFun(phi,y):\n",
    "    m=len(y);#no of data points\n",
    "    n=len(phi[0]);# no. of features    \n",
    "    alpha=0.22;# learning parameter\n",
    "    maxIteration=10000;\n",
    "    phi=np.array(phi);\n",
    "    y=(np.array(y));#converting row vector to col vector    \n",
    "    wk0=np.zeros(n);# Nx1 vector\n",
    "    phiT=np.transpose(phi);\n",
    "    phiTphi=np.dot(phiT,phi);   \n",
    "    phiTy=np.dot(phiT,y);   \n",
    "    alphaBym=alpha/m;\n",
    "    xaxis=list();\n",
    "    yaxis=list();\n",
    "    #----------------------\n",
    "    print(\"Training Started (Least Sq. Without Regularlization) ...\");\n",
    "    for i in range(maxIteration):  \n",
    "        wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)));                \n",
    "        ystar=pridict(phi,wk1);\n",
    "        rms=getRMS(y,ystar);    \n",
    "        xaxis.append(i);\n",
    "        yaxis.append(rms);\n",
    "        percentComplete=((i+1)*100)/maxIteration;\n",
    "        if( percentComplete%10==0 ):\n",
    "            print(\"Percent Completed\",percentComplete);\n",
    "        wk0=wk1;\n",
    "    print(\"Final Trained RMS:\",rms);\n",
    "    plotGraph(xaxis,yaxis);\n",
    "    return wk1;\n",
    "    pass;\n",
    "\n",
    "\n",
    "\n",
    "#wStart=gardientDescentWithRidge(trainDatasetPhi,trainDatasetY);\n",
    "#wStart=gardientDescentWithPnom(trainDatasetPhi,trainDatasetY,4);\n",
    "#mainRidgeClosedFormSol();\n",
    "\n",
    "a=np.array([[3,4],[12,13]]);\n",
    "b=np.array([1,2]);\n",
    "c=a-b;\n",
    "c=np.sum(a,axis=1);\n",
    "sigma=1;\n",
    "c=np.power(c,2);\n",
    "c=c*(-1*(1/sigma));\n",
    "c=np.exp(c);\n",
    "d=np.insert(a,len(a[0]),b,axis=1);\n",
    "print(a[:,1]*a[:,0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Trained Dataset from file...\n",
      "Normalizing Phi...\n",
      "Normalization done.\n",
      "Normalizing Phi...\n",
      "Normalization done.\n",
      "Fetching of data Completed.\n",
      "Train Size:280\n",
      "Validate Size:120\n",
      "Closed FormSol With Trained Data Ridge RMS  2.6147993385918764\n",
      "Closed FormSol With validate Ridge RMS: 4.40155464969092\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mainClosedFormSol(dataset):\n",
    "    \n",
    "    tdsPhi=dataset[0];\n",
    "    tdsY=dataset[1];\n",
    "    vdsPhi=dataset[2];\n",
    "    vdsY=dataset[3];\n",
    "    ttds=dataset[4];\n",
    "    #--------------------[Closed Form Sol without Regularlization]--------------------------------\n",
    "    #Find w*\n",
    "    wStar=trainUsingClosedFormEquation(tdsPhi,tdsY);\n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(vdsPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(vdsY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(ttds,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Closed Form Solution RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    pass;\n",
    "\n",
    "\n",
    "def mainRidgeClosedFormSol(dataset,lam):\n",
    "    #-------------------------------------\n",
    "    # Best value: m=300 validate=120\n",
    "    #-------------------------------------    \n",
    "    tdsPhi=dataset[0];\n",
    "    tdsY=dataset[1];\n",
    "    vdsPhi=dataset[2];\n",
    "    vdsY=dataset[3];\n",
    "    ttds=dataset[4];\n",
    "    #--------------------[Closed Form Sol without Regularlization]--------------------------------\n",
    "    #Find w*\n",
    "    wStar=trainUsingClosedFormRidgeEq(tdsPhi,tdsY,lam=lam);\n",
    "    \n",
    "    ystar=pridict(tdsPhi,wStar);\n",
    "    rms=getRMS(tdsY,ystar);\n",
    "    print(\"Closed FormSol With Trained Data Ridge RMS \",rms);\n",
    "    \n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(vdsPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(vdsY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(ttds,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Closed FormSol With validate Ridge RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    pass;\n",
    "\n",
    "def mainGradientDesent(dataset,lamdaVal=0.0001,alphaVal=0.0003):\n",
    "    tdsPhi=dataset[0];\n",
    "    tdsY=dataset[1];\n",
    "    vdsPhi=dataset[2];\n",
    "    vdsY=dataset[3];\n",
    "    ttds=dataset[4];\n",
    "    #--------------------[Gradient decent without Regularlization]--------------------------------\n",
    "    wStar=gardientDescentWithRidge(tdsPhi,tdsY,lam=lamdaVal,alpha=alphaVal);\n",
    "    #wStar=gardientDescentWithPnom(trainDatasetPhi,trainDatasetY,(4/3));\n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(vdsPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(vdsY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(ttds,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Gradient Desent ||Norm||=2 RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "def mainGradientDesentLpnorm(dataset,pnorm):\n",
    "    tdsPhi=dataset[0];\n",
    "    tdsY=dataset[1];\n",
    "    vdsPhi=dataset[2];\n",
    "    vdsY=dataset[3];\n",
    "    ttds=dataset[4];\n",
    "    #--------------------[Gradient decent without Regularlization]--------------------------------\n",
    "    wStar=gardientDescentWithPnom(tdsPhi,tdsY,pnorm);\n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(vdsPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(vdsY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(ttds,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Gradient Desent ||Norm||=\",pnorm,\" RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    \n",
    "#split train data into Train and Validate\n",
    "def spitTrainDataset(phi,y,tdSize=300):\n",
    "    m=len(phi);        \n",
    "    tdsSize=int(m*trainDSSizePercentage);\n",
    "    l=tdSize;    \n",
    "    trainDatasetPhi=phi[0:l];\n",
    "    trainDatasetY=y[0:l];\n",
    "    validateDatasetPhi=phi[tdsSize:m];\n",
    "    validateDatasetY=y[tdsSize:m];    \n",
    "   \n",
    "    return [trainDatasetPhi,trainDatasetY,validateDatasetPhi,validateDatasetY];    \n",
    "    pass\n",
    "\n",
    "\n",
    "# GD: Least Sq. With Ridges\n",
    "def gardientDescentWithRidge(phi,y,lam,alpha,wi=-1):\n",
    "    m=len(y);#no of data points\n",
    "    n=len(phi[0]);# no. of features    \n",
    "    #alpha=.000000000003; #learning parameter\n",
    "    maxIteration=1000000;\n",
    "    phi=np.array(phi);\n",
    "    y=(np.array(y));#converting row vector to col vector    \n",
    "    if(wi==-1):\n",
    "        wk0=np.zeros(n);# Nx1 vector\n",
    "    else:\n",
    "        wk0=phi[wi]\n",
    "    \n",
    "    phiT=np.transpose(phi);\n",
    "    phiTphi=np.dot(phiT,phi);   \n",
    "    phiTy=np.dot(phiT,y);   \n",
    "    alphaBym=alpha/m;\n",
    "    xaxis=list();\n",
    "    yaxis=list();\n",
    "    algFixedIteration=True;\n",
    "    logReading=True;\n",
    "    diff=0;\n",
    "    #-----------------------------------------------------------------\n",
    "    #Best Tested Constant\n",
    "    #1)With 13 features i.e original Phi\n",
    "    #normalize phi: true.\n",
    "    #aplha=.212 lamda=.301 tds=300 vds=120 trained o/p=4.8310 rms\n",
    "    #Note: Tried for different initial wk0 from phi matrix but o/p remain same\n",
    "    #\n",
    "    #2)With 26 features i.e newphi=phi + phi^2\n",
    "    #normalize phi: true; algFixedIteration=True; maxIteration=1000000;\n",
    "    #aplha=.0003 lamda=.301 tds=300 vds=120 trained o/p=3.940800315632070 rms\n",
    "    #Tried for different initial wk0 but o/p remain same\n",
    "    #-----------------------------------------------------------------\n",
    "    print(\"Training Started (Least Sq. With Ridge) ...\");\n",
    "    if (algFixedIteration):\n",
    "        for iteration in range(0,maxIteration):  \n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0)));              \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            percentComplete=((iteration+1)*100)/maxIteration;\n",
    "            if( percentComplete%10==0 ):\n",
    "                print(\"Percent Completed\",percentComplete,\"rms:\",rms);                \n",
    "            wk0=wk1;\n",
    "    else:\n",
    "        diffOffset=1e-12;\n",
    "        iteration=0;\n",
    "        oldRms=0;\n",
    "        voldRms=0;\n",
    "        while (True):\n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0)));                     \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            diff=abs(oldRms-rms);            \n",
    "            if(iteration>0 and diff<diffOffset):\n",
    "                break;\n",
    "            if(False and iteration%100==0 ):\n",
    "                print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff);            \n",
    "            wk0=wk1;\n",
    "            oldRms=rms;\n",
    "            iteration+=1;\n",
    "        print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff);    \n",
    "           \n",
    "    print(\"Final Trained RMS:\",rms ,\". Iteration needed \", iteration);    \n",
    "    #-------------------------------------------------------------\n",
    "    if(logReading):\n",
    "        writeReadingInFile(\"ridge1.csv\",alpha,lam,iteration,rms,2);\n",
    "    plotGraph(xaxis,yaxis);\n",
    "    return wk1;\n",
    "\n",
    "\n",
    "# GD: Least Sq. With ||w||_(1.5)^(1.5)\n",
    "def gardientDescentWithPnom(phi,y,p):\n",
    "    m=len(y);#no of data points\n",
    "    n=len(phi[0]);# no. of features    \n",
    "    alpha=0.0003 #learning parameter\n",
    "    maxIteration=1000000;\n",
    "    phi=np.array(phi);\n",
    "    y=(np.array(y));#converting row vector to col vector    \n",
    "    wk0=np.zeros(n);# Nx1 vector    \n",
    "    wk0=phi[1];\n",
    "    phiT=np.transpose(phi);\n",
    "    phiTphi=np.dot(phiT,phi);   \n",
    "    phiTy=np.dot(phiT,y);   \n",
    "    alphaBym=alpha/m;\n",
    "    lam=0.31;\n",
    "    xaxis=list();\n",
    "    yaxis=list();\n",
    "    algFixedIteration=True;\n",
    "    logReading=True;\n",
    "    diff=0;\n",
    "    wPow=p-1;\n",
    "    if (p<=1):\n",
    "        print(\"Error: norm p is less than 1 i.p p=\",wPow);\n",
    "        return None;\n",
    "        \n",
    "    #-----------------------------------------------------------------\n",
    "    print(\"Training Started (Least Sq. With Ridge) ...\");\n",
    "    if (algFixedIteration):\n",
    "        for iteration in range(0,maxIteration):\n",
    "            if (wPow>1):\n",
    "                wk0Pow=np.power(wk0,wPow);            \n",
    "            else:\n",
    "                wk0Pow=wk0;\n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0Pow))); \n",
    "            \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            percentComplete=((iteration+1)*100)/maxIteration;\n",
    "            if( percentComplete%10==0 ):\n",
    "                print(\"Percent Completed\",percentComplete,\" rms:\",rms);\n",
    "            wk0=wk1;\n",
    "    else:\n",
    "        diffOffset=1e-20;\n",
    "        iteration=0;\n",
    "        oldRms=0;\n",
    "        voldRms=0;\n",
    "        while (True):            \n",
    "            if (wPow>1):\n",
    "                wk0Pow=np.power(wk0,wPow);            \n",
    "            else:\n",
    "                wk0Pow=wk0;\n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0Pow)));  \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            diff=abs(oldRms-rms);                      \n",
    "            \n",
    "            if(iteration>0 and  diff<=diffOffset):\n",
    "                break;\n",
    "            if(False and iteration%100==0 ):\n",
    "                print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff);            \n",
    "            wk0=wk1;\n",
    "            oldRms=rms;            \n",
    "            iteration+=1;\n",
    "        print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff);    \n",
    "\n",
    "    print(\"Final Trained RMS:\",rms ,\". Iteration needed \", iteration);       \n",
    "    #-------------------------------------------------------------\n",
    "    if(logReading):\n",
    "        writeReadingInFile(\"pnom.csv\",alpha,lam,iteration,rms,p);\n",
    "    plotGraph(xaxis,yaxis);\n",
    "    return wk1; \n",
    "\n",
    "# Finding w*=(QTQ+lamI)^-1QTY\n",
    "def trainUsingClosedFormRidgeEq(dataset,output,lam=0.0001):\n",
    "    #-------------------------------------\n",
    "    # 1)Best value: m=300 validate=120\n",
    "    # addW0=True: c=0.376654. Not lamd\n",
    "    # Note: Please make eq as phiT_phi+c\n",
    "    #\n",
    "    # 2)Best value: m=300 validate=120\n",
    "    # addW0=True: lam=0.521. Not C. \n",
    "    # trained RMS:  3.938231279881311\n",
    "    # Note: Please make eq as phiT_phi+lamI\n",
    "    #-------------------------------------\n",
    "    m=len(dataset);\n",
    "    n=len(dataset[0]);    \n",
    "    phi=np.array(dataset);\n",
    "    y=np.array(output);\n",
    "    phiT=np.transpose(phi);    \n",
    "    #(QTQ)    \n",
    "    phiT_phi=np.dot(phiT,phi);\n",
    "    n=len(phiT_phi);    \n",
    "    c=.301;\n",
    "    I=np.identity(n);\n",
    "    lamI=lam*I;\n",
    "    d=getDet(phiT_phi)\n",
    "    #--------------------------------------\n",
    "    if(True or d>0):\n",
    "        #(QTQ+lamI)^-1\n",
    "        phiT_phi_inv=inv((phiT_phi+lamI));\n",
    "        #(QTQ+lamI)^-1QT\n",
    "        phiT_phi_inv_phiT=np.dot(phiT_phi_inv,phiT);  \n",
    "        #(QTQ+lamI)^-1QT*Y\n",
    "        w=np.dot(phiT_phi_inv_phiT,y);\n",
    "        return w;\n",
    "    else:\n",
    "        print(\"Error:Phi is NOT full column rank.\");\n",
    "        return None;\n",
    "    pass;\n",
    "\n",
    "\n",
    "\n",
    "def getKernalFeature(phi,wrtdataPoint):    \n",
    "    p=np.array(phi);           \n",
    "    wrtdata=np.array(phiSet[wrtdataPoint]);     \n",
    "    tempMatrix=p-wrtdata;    \n",
    "    fcol=np.sum(tempMatrix,axis=1);\n",
    "    sigma=2;\n",
    "    fcol=np.power(fcol,2);\n",
    "    fcol=fcol*(-1*(1/sigma));\n",
    "    fcol=np.exp(fcol);    \n",
    "    return fcol;\n",
    "    pass;\n",
    "\n",
    "\n",
    "def createNewFeatureMatrix(phi,maxDeg=4):    \n",
    "    newPhi=np.array(phi);\n",
    "    p=np.array(phi);        \n",
    "    if(addW0Col):#deleting first W0Col coffecient is 1\n",
    "        p=np.delete(p,0,1);    \n",
    "    \n",
    "    #---------------------------------------------------------------------------------\n",
    "    #Best Features till now.\n",
    "    #1. feature sq2 with lamda 0.001\n",
    "    #2. feature sq2 + sq root with lamda 0.001\n",
    "    #3. feature sq2 + 1/2 root + 1/4 root with lamda 0.001 rms: 3.02849\n",
    "    #4. feature sq2 + 1/2 root + 1/4 root + 1/8 + 1/16 lamda=0.0001\n",
    "    #5. feature sq2 + 1/2 root + 1/4 root + 1/8 + 1/16 + [x0.x1 x0.x2 x0.x3 x0.x4 ....] lamda=0.0001\n",
    "    #6. feature sq2 + 1/2 root + 1/4 root + 1/8 + 1/16 + [x0.x1 x0.x2 ....] +[x0.x1^2 x0.x2^2 ] lamda=0.0001\n",
    "    # train rms= 2.732538945291264 validate Rms=4.711844963854281 test RMS=3.014\n",
    "    #7. feature sq2 + 1/2 root + 1/4 root + 1/8 + 1/16 + [x0.x1 x0.x1 ....] +[x0.x1^2 x0.x2^2 ] \n",
    "    #[x3.x4^0.05 x3.x5^0.05]\n",
    "    #lamda=0.0001 train rms= 2.6523470519008407 validate Rms=4.490001110608855 test RMS=2.85636\\\n",
    "    #8.feature sq2 + 1/2 root + 1/4 root + 1/8 + 1/16 + [x0.x1 x0.x1 ....] +[x0.x1^2 x0.x2^2 ] \n",
    "    # + [x3.x4^0.5 x3.x5^0.5]\n",
    "    #9.feature sq2 + 1/2 root + 1/4 root + 1/8 + 1/16 + [x0.x1 x0.x1 ....] +[x0.x1^2 x0.x2^2 ] \n",
    "    # + [x3.x4^0.5 x3.x5^0.5] + [x3.x4^2.x5^0.4 x3.x4^2.x6^0.4 ..]     \n",
    "    #lamda=0.0001 train rms=2.6147993385918764 validate Rms=2.6147993385918764\n",
    "    #--------------------------------------------------------------------------------\n",
    "    \n",
    "    pPowI=np.power(p,2);        \n",
    "    newPhi=np.concatenate((newPhi,pPowI),axis=1);     \n",
    "   \n",
    "    pPowI=np.abs(p);    \n",
    "    pPowI=np.power(pPowI,0.5);        \n",
    "    newPhi=np.concatenate((newPhi,pPowI),axis=1); \n",
    "    \n",
    "    pPowI=np.abs(p);    \n",
    "    pPowI=np.power(pPowI,0.25);        \n",
    "    newPhi=np.concatenate((newPhi,pPowI),axis=1); \n",
    "   \n",
    "    pPowI=np.abs(p);    \n",
    "    pPowI=np.power(pPowI,0.125);        \n",
    "    newPhi=np.concatenate((newPhi,pPowI),axis=1); \n",
    "   \n",
    "    pPowI=np.abs(p);    \n",
    "    pPowI=np.power(pPowI,0.0625);        \n",
    "    newPhi=np.concatenate((newPhi,pPowI),axis=1); \n",
    "   \n",
    "    pPowI=np.abs(p);    \n",
    "    pPowI=np.power(pPowI,0.03125);        \n",
    "    newPhi=np.concatenate((newPhi,pPowI),axis=1); \n",
    "\n",
    "    #pPowI=np.power(p,4);        \n",
    "    #newPhi=np.concatenate((newPhi,pPowI),axis=1); \n",
    "    \n",
    "    #newPhi=np.insert(newPhi,len(newPhi[0]),getKernalFeature(phi,399),axis=1);\n",
    "    c1=p[:,0];        \n",
    "    n=int(len(p[0])/2)+1;  \n",
    "    for i in range(1,n):\n",
    "        #c1=p[:,i];\n",
    "        #c1=np.abs(c1);\n",
    "        c2=p[:,i+1];\n",
    "        #c2=np.abs(c2);\n",
    "        #c2=np.power(c2,2);        \n",
    "        c3=c1*c2;\n",
    "        newPhi=np.insert(newPhi,len(newPhi[0]),c3,axis=1);    \n",
    "    \n",
    "    c1=p[:,0];      \n",
    "    c2=p[:,1];\n",
    "    n=int(len(p[0])/3)+1;  \n",
    "    for i in range(2,0):#!!!!\n",
    "        #c1=p[:,i];\n",
    "        #c1=np.abs(c1);        \n",
    "        c3=p[:,i+1];\n",
    "        #c2=np.abs(c2);\n",
    "        #c2=np.power(c2,2);        \n",
    "        c=c1*c2*c3;\n",
    "        newPhi=np.insert(newPhi,len(newPhi[0]),c,axis=1);    \n",
    "    \n",
    "    \n",
    "    c1=p[:,0];        \n",
    "    n=int(len(p[0])/2)+1;  \n",
    "    pPowI=np.power(p,2);                \n",
    "    for i in range(1,n):\n",
    "        c2=pPowI[:,i+1];\n",
    "        c3=c1*c2;\n",
    "        newPhi=np.insert(newPhi,len(newPhi[0]),c3,axis=1);    \n",
    "    \n",
    "    c1=p[:,3];        \n",
    "    n=int(len(p[0])/2)+1;  \n",
    "    pPowI=np.abs(p);    \n",
    "    pPowI=np.power(pPowI,0.5);                \n",
    "    for i in range(4,n):#!!!!\n",
    "        c2=pPowI[:,i];\n",
    "        c3=c1*c2;\n",
    "        newPhi=np.insert(newPhi,len(newPhi[0]),c3,axis=1);    \n",
    "    \n",
    "    c1=p[:,3];      \n",
    "    c2=p[:,4]**2;\n",
    "    n=int(len(p[0])/2)+1;              \n",
    "    pPowI=np.abs(p);     \n",
    "    pPowI=np.power(pPowI,0.4);                \n",
    "    for i in range(5,n):#!!!!\n",
    "        c3=pPowI[:,i];\n",
    "        c=c1*c2*c3;\n",
    "        newPhi=np.insert(newPhi,len(newPhi[0]),c,axis=1);    \n",
    "    \n",
    "    \n",
    "    return newPhi;    \n",
    "    pass;\n",
    "\n",
    "#--settings--\n",
    "np.set_printoptions(suppress=True)\n",
    "#---init---\n",
    "dir=\"\"\n",
    "trainFile=dir+\"train.csv\";\n",
    "testFile=dir+\"test.csv\";\n",
    "trainDSSizePercentage=0.7; # x*100 percentage. 1-x data set will be used for validating\n",
    "addW0Col=True;\n",
    "tdSize=280;\n",
    "#---------------------------------------------\n",
    "print(\"Fetching Trained Dataset from file...\");\n",
    "dataset=readTrainData(trainFile);\n",
    "testDS=readTestData(testFile);\n",
    "phiSet=dataset[0];\n",
    "ySet=dataset[1];\n",
    "phiSet_norm=normalizePhi(phiSet);\n",
    "testDS_norm=normalizePhi(testDS);\n",
    "tds=spitTrainDataset(phiSet,ySet,tdSize);\n",
    "tds_norm=spitTrainDataset(phiSet_norm,ySet,tdSize);\n",
    "\n",
    "print(\"Fetching of data Completed.\");\n",
    "\n",
    "#train set\n",
    "trainDatasetPhi=tds[0];\n",
    "trainDatasetY=tds[1];\n",
    "validateDatasetPhi=tds[2];\n",
    "validateDatasetY=tds[3];\n",
    "gtdPhi=trainDatasetPhi;\n",
    "\n",
    "trainDatasetPhi_norm=tds_norm[0];\n",
    "trainDatasetY_norm=tds_norm[1];\n",
    "validateDatasetPhi_norm=tds_norm[2];\n",
    "validateDatasetY_norm=tds_norm[3];\n",
    "\n",
    "\n",
    "deg=2;\n",
    "trainDatasetPhi_norm=createNewFeatureMatrix(trainDatasetPhi_norm,deg);\n",
    "validateDatasetPhi_norm=createNewFeatureMatrix(validateDatasetPhi_norm,deg);\n",
    "testDS_norm=createNewFeatureMatrix(testDS_norm,deg);\n",
    "\n",
    "deg=2;\n",
    "trainDatasetPhi=createNewFeatureMatrix(trainDatasetPhi,deg);\n",
    "validateDatasetPhi=createNewFeatureMatrix(validateDatasetPhi,deg);\n",
    "testDS=createNewFeatureMatrix(testDS,deg);\n",
    "\n",
    "print(\"Train Size:\"+str(len(trainDatasetPhi)));\n",
    "print(\"Validate Size:\"+str(len(validateDatasetPhi)));\n",
    "\n",
    "ds=[trainDatasetPhi,trainDatasetY,validateDatasetPhi,validateDatasetY,testDS];\n",
    "ds_norm=[trainDatasetPhi_norm,trainDatasetY,validateDatasetPhi_norm,validateDatasetY,testDS_norm];\n",
    "#mainClosedFormSol(ds);\n",
    "mainRidgeClosedFormSol(ds,0.0001);\n",
    "#mainGradientDesent(ds_norm,lamdaVal=0.0001,alphaVal=0.0003);\n",
    "#mainGradientDesentLpnorm(ds_norm,8/5);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
