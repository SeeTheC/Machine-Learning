{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "from numpy.linalg import inv;\n",
    "from numpy.linalg import det;\n",
    "import math;\n",
    "\n",
    "# Will read the file and convert it into two dataset one train data other validate data\n",
    "def readTrainData(fileName):\n",
    "    row_index=0;\n",
    "    phi=list();\n",
    "    y=list();\n",
    "    with open(fileName) as f:\n",
    "        for line in f:\n",
    "            if row_index >0:\n",
    "                phi_i=list((float(n) for n in line.split('\\n')[0].split(\",\") ));\n",
    "                if(addW0Col):\n",
    "                    phi_i[0]=1;\n",
    "                else:# removing id col.\n",
    "                    phi_i.pop();\n",
    "                # last row is value of yi                \n",
    "                y_i=phi_i.pop(len(phi_i)-1); \n",
    "                phi.append(phi_i);             \n",
    "                y.append(y_i);\n",
    "            row_index+=1;\n",
    "    return [phi,y];\n",
    "#End-readTrainData\n",
    "\n",
    "# Will read the file and convert it into dataset for Testing the Model\n",
    "def readTestData(fileName):\n",
    "    row_index=0;\n",
    "    phi=list();\n",
    "    y=list();\n",
    "    with open(fileName) as f:\n",
    "        for line in f:\n",
    "            if row_index >0:                \n",
    "                phi_i=list((float(n) for n in line.split('\\n')[0].split(\",\") ));\n",
    "                if(addW0Col):\n",
    "                    phi_i[0]=1;\n",
    "                else:# removing id col.\n",
    "                    phi_i.pop();                \n",
    "                phi.append(phi_i);                             \n",
    "            row_index+=1;\n",
    "    m=len(phi);    \n",
    "    return phi;\n",
    "#End-readTrainData\n",
    "\n",
    "\n",
    "\n",
    "#write-output\n",
    "def writeTestData(ystar):\n",
    "    fo = open(\"output.csv\", \"w\");    \n",
    "    fo.write(\"ID,MEDV\\n\");\n",
    "    m=len(ystar);\n",
    "    for i in range(m):\n",
    "        fo.write(str(i)+\",\"+str(ystar[i])+\"\\n\");\n",
    "    fo.close();\n",
    "    pass;\n",
    "\n",
    "# Return det of matrix\n",
    "def getDet(A):\n",
    "    d=det(A);\n",
    "    if(d<10**-10):\n",
    "        return 0;\n",
    "    return d;\n",
    "\n",
    "\n",
    "#Return RMS: root mean square error\n",
    "def getRMS(y,yStar):\n",
    "    m=len(y);\n",
    "    sigma=0;\n",
    "    for i in range(m):\n",
    "        delta=(y[i]-yStar[i]);\n",
    "        delta=delta*delta;\n",
    "        sigma=sigma+delta;\n",
    "    meanSq=sigma/m;   \n",
    "    rms=math.sqrt(meanSq);\n",
    "    return rms;\n",
    "    pass;\n",
    "\n",
    "#For ploting graph of RMS VS Iteration\n",
    "def plotGraph(x,y):\n",
    "    import matplotlib.pyplot as plt;\n",
    "    plt.plot(x,y)\n",
    "    plt.ylabel('rms')\n",
    "    plt.xlabel('iteration');\n",
    "    plt.show();\n",
    "    pass;\n",
    "\n",
    "#Record readings for gradient descent\n",
    "def writeReadingInFile(filename,alpha,lam,iteration,rms,p):\n",
    "    import os.path;\n",
    "    import datetime;\n",
    "    import time;\n",
    "    ts = datetime.datetime.fromtimestamp(time.time()).strftime('%d-%m-%Y %H:%M:%S')\n",
    "    if(os.path.exists(filename)==False):\n",
    "        fo = open(filename, \"w\"); \n",
    "        fo.write(\"iteration,norm,alpha,lam,rms,timestamp\\n\");\n",
    "        fo.write(str(iteration)+\",\"+str(p)+\",\"+str(alpha)+\",\"+str(lam)+\",\"+str(rms)+\",\"+str(ts)+\"\\n\");\n",
    "    else:\n",
    "        fo = open(filename, \"a\"); \n",
    "        fo.write(str(iteration)+\",\"+str(p)+\",\"+str(alpha)+\",\"+str(lam)+\",\"+str(rms)+\",\"+str(ts)+\"\\n\");\n",
    "    fo.close();                    \n",
    "    pass;\n",
    "\n",
    "\n",
    "#normalize the data set ny (x-u)/s where s is max-min\n",
    "def normalizePhi(unNormalizedPhi):    \n",
    "    phi=np.array(unNormalizedPhi);\n",
    "    print(\"Normalizing Phi...\");  \n",
    "    std=phi.std(0);\n",
    "    mean=phi.mean(0); \n",
    "    if(addW0Col):#making first col. mean as 0              \n",
    "        std[0]=1;\n",
    "        mean[0]=0;\n",
    "    phi_normalize=(phi-mean)/std;    \n",
    "    print(\"Normalization done.\");\n",
    "    return phi_normalize;\n",
    "    pass;\n",
    "\n",
    "#pridict of y* given w* QW=y*\n",
    "def pridict(dataset,weight):\n",
    "    phi=np.array(dataset);\n",
    "    w=np.array(weight);\n",
    "    ystar=np.dot(phi,w);\n",
    "    return ystar;\n",
    "    pass;\n",
    "\n",
    "# Finding w*=(QTQ)^-1QTY\n",
    "def trainUsingClosedFormEquation(dataset,output):\n",
    "    m=len(dataset);\n",
    "    n=len(dataset[0]);\n",
    "    print(\"------------------\");\n",
    "    #print(dataset);\n",
    "    phi=np.array(dataset);\n",
    "    print(\"------------------\");\n",
    "    #print(phi);    \n",
    "    y=np.array(output);\n",
    "    phiT=np.transpose(phi);\n",
    "    #(QTQ)    \n",
    "    phiT_phi=np.dot(phiT,phi);   \n",
    "    d=getDet(phiT_phi)\n",
    "    if(d>0):\n",
    "        #(QTQ)^-1\n",
    "        phiT_phi_inv=inv(phiT_phi);\n",
    "        #(QTQ)^-1QT\n",
    "        phiT_phi_inv_phiT=np.dot(phiT_phi_inv,phiT);  \n",
    "        #(QTQ)^-1QT*Y\n",
    "        w=np.dot(phiT_phi_inv_phiT,y);\n",
    "        return w;\n",
    "    else:\n",
    "        print(\"Error:Phi is NOT full column rank.\");\n",
    "        return None;\n",
    "    pass;\n",
    "\n",
    "\n",
    "\n",
    "def numpiTestFun():\n",
    "    A2= np.matrix([[4,6],[2,8]])        \n",
    "    A3= np.matrix([[1,2,3],[4,5,7],[7,8,9]])\n",
    "    A=A2;\n",
    "    print(A);\n",
    "    print(np.power(A,0.5));\n",
    "    print(A);\n",
    "    print(\"Det(A):\"+str(getDet(A)));\n",
    "    B= np.transpose(A);\n",
    "    C=inv(A);\n",
    "    #print(C);\n",
    "    print(np.dot(A,C));\n",
    "    print(A.std(0));\n",
    "    print(A.mean(0));\n",
    "    print(normalizePhi(A));\n",
    "    norm=(A-A.mean(0))/A.std(0);    \n",
    "    print(norm);    \n",
    "    print();\n",
    "    pass;\n",
    "\n",
    "\n",
    "# Finding w*=(QTQ+lamI)^-1QTY\n",
    "def trainUsingClosedFormRidgeEq(dataset,output):\n",
    "    #-------------------------------------\n",
    "    # Best value: m=300 validate=120\n",
    "    # addW0=True: c=0.376654. Not lamd\n",
    "    #-------------------------------------\n",
    "    m=len(dataset);\n",
    "    n=len(dataset[0]);    \n",
    "    phi=np.array(dataset);\n",
    "    y=np.array(output);\n",
    "    phiT=np.transpose(phi);    \n",
    "    #(QTQ)    \n",
    "    phiT_phi=np.dot(phiT,phi);\n",
    "    n=len(phiT_phi);\n",
    "    lam=0.5;\n",
    "    c=.376654;\n",
    "    I=np.identity(n);\n",
    "    lamI=lam*I;\n",
    "    d=getDet(phiT_phi)\n",
    "    #--------------------------------------\n",
    "    if(d>0):\n",
    "        #(QTQ+lamI)^-1\n",
    "        phiT_phi_inv=inv((phiT_phi+c));\n",
    "        #(QTQ+lamI)^-1QT\n",
    "        phiT_phi_inv_phiT=np.dot(phiT_phi_inv,phiT);  \n",
    "        #(QTQ+lamI)^-1QT*Y\n",
    "        w=np.dot(phiT_phi_inv_phiT,y);\n",
    "        return w;\n",
    "    else:\n",
    "        print(\"Error:Phi is NOT full column rank.\");\n",
    "        return None;\n",
    "    pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GD: Least Sq. Without Regularlization\n",
    "def gardientDescentErrorFun(phi,y):\n",
    "    m=len(y);#no of data points\n",
    "    n=len(phi[0]);# no. of features    \n",
    "    alpha=0.22;# learning parameter\n",
    "    maxIteration=10000;\n",
    "    phi=np.array(phi);\n",
    "    y=(np.array(y));#converting row vector to col vector    \n",
    "    wk0=np.zeros(n);# Nx1 vector\n",
    "    phiT=np.transpose(phi);\n",
    "    phiTphi=np.dot(phiT,phi);   \n",
    "    phiTy=np.dot(phiT,y);   \n",
    "    alphaBym=alpha/m;\n",
    "    xaxis=list();\n",
    "    yaxis=list();\n",
    "    #----------------------\n",
    "    print(\"Training Started (Least Sq. Without Regularlization) ...\");\n",
    "    for i in range(maxIteration):  \n",
    "        wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)));                \n",
    "        ystar=pridict(phi,wk1);\n",
    "        rms=getRMS(y,ystar);    \n",
    "        xaxis.append(i);\n",
    "        yaxis.append(rms);\n",
    "        percentComplete=((i+1)*100)/maxIteration;\n",
    "        if( percentComplete%10==0 ):\n",
    "            print(\"Percent Completed\",percentComplete);\n",
    "        wk0=wk1;\n",
    "    print(\"Final Trained RMS:\",rms);\n",
    "    plotGraph(xaxis,yaxis);\n",
    "    return wk1;\n",
    "    pass;\n",
    "\n",
    "\n",
    "# GD: Least Sq. With Ridges\n",
    "def gardientDescentWithRidge(phi,y,wi=-1):\n",
    "    m=len(y);#no of data points\n",
    "    n=len(phi[0]);# no. of features    \n",
    "    alpha=0.21;# learning parameter\n",
    "    maxIteration=10000;\n",
    "    phi=np.array(phi);\n",
    "    y=(np.array(y));#converting row vector to col vector    \n",
    "    if(wi==-1):\n",
    "        wk0=np.zeros(n);# Nx1 vector\n",
    "    else:\n",
    "        wk0=phi[wi]\n",
    "    \n",
    "    phiT=np.transpose(phi);\n",
    "    phiTphi=np.dot(phiT,phi);   \n",
    "    phiTy=np.dot(phiT,y);   \n",
    "    alphaBym=alpha/m;\n",
    "    lam=0.301;    \n",
    "    xaxis=list();\n",
    "    yaxis=list();\n",
    "    algFixedIteration=True;\n",
    "    logReading=True;\n",
    "    diff=0;\n",
    "    #-----------------------------------------------------------------\n",
    "    #Best Tested Constant\n",
    "    #aplha=.212 lamda=.301 datasie=0.7 o/p=4.8310 rms\n",
    "    #Tried for different initial wk0 but o/p remain same\n",
    "    #-----------------------------------------------------------------\n",
    "    print(\"Training Started (Least Sq. With Ridge) ...\");\n",
    "    if (algFixedIteration):\n",
    "        for iteration in range(0,maxIteration):  \n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0)));   \n",
    "            print(wk1);\n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            percentComplete=((iteration+1)*100)/maxIteration;\n",
    "            if( percentComplete%10==0 ):\n",
    "                print(\"Percent Completed\",percentComplete);\n",
    "            wk0=wk1;\n",
    "    else:\n",
    "        diffOffset=1e-20;\n",
    "        iteration=0;\n",
    "        oldRms=0;\n",
    "        voldRms=0;\n",
    "        while (True):\n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0)));                     \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            diff=abs(oldRms-rms);            \n",
    "            if(iteration>0 and diff<diffOffset):\n",
    "                break;\n",
    "            if(False and iteration%100==0 ):\n",
    "                print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff);            \n",
    "            wk0=wk1;\n",
    "            oldRms=rms;\n",
    "            iteration+=1;\n",
    "        print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff);    \n",
    "           \n",
    "    print(\"Final Trained RMS:\",rms ,\". Iteration needed \", iteration);    \n",
    "    #-------------------------------------------------------------\n",
    "    if(logReading):\n",
    "        writeReadingInFile(\"ridge1.csv\",alpha,lam,iteration,rms,2);\n",
    "    #plotGraph(xaxis,yaxis);\n",
    "    return wk1;\n",
    "\n",
    "def mainRidgeGradientDescent():\n",
    "    print(\"Training started\");\n",
    "    m=len(trainDatasetPhi);\n",
    "    vl=[];\n",
    "    for i in range(m):\n",
    "        wStar=gardientDescentWithRidge(trainDatasetPhi,trainDatasetY,i);\n",
    "        ystar=pridict(validateDatasetPhi,wStar);\n",
    "        #checking for RMS for Validate Data\n",
    "        rms=getRMS(validateDatasetY,ystar);\n",
    "        writeReadingInFile(\"wkridge1.csv\",0,0,i,rms,2);\n",
    "        vl.append(rms)\n",
    "        print(\"Wk=:\",i);\n",
    "    nparr=np.array(vl);\n",
    "    print(\"Completed:\",nparr.min());\n",
    "    pass\n",
    "\n",
    "# GD: Least Sq. With ||w||_(1.5)^(1.5)\n",
    "def gardientDescentWithPnom(phi,y,p):\n",
    "    m=len(y);#no of data points\n",
    "    n=len(phi[0]);# no. of features    \n",
    "    alpha=0.2 #learning parameter\n",
    "    maxIteration=100000;\n",
    "    phi=np.array(phi);\n",
    "    y=(np.array(y));#converting row vector to col vector    \n",
    "    wk0=np.zeros(n);# Nx1 vector    \n",
    "    wk0=phi[1];\n",
    "    phiT=np.transpose(phi);\n",
    "    phiTphi=np.dot(phiT,phi);   \n",
    "    phiTy=np.dot(phiT,y);   \n",
    "    alphaBym=alpha/m;\n",
    "    lam=0.31;\n",
    "    xaxis=list();\n",
    "    yaxis=list();\n",
    "    algFixedIteration=False;\n",
    "    logReading=True;\n",
    "    diff=0;\n",
    "    wPow=p-1;\n",
    "    if (p<=1):\n",
    "        print(\"Error: norm p is less than 1 i.p p=\",wPow);\n",
    "        return None;\n",
    "        \n",
    "    #-----------------------------------------------------------------\n",
    "    print(\"Training Started (Least Sq. With Ridge) ...\");\n",
    "    if (algFixedIteration):\n",
    "        for iteration in range(0,maxIteration):\n",
    "            if (wPow>1):\n",
    "                wk0Pow=np.power(wk0,wPow);            \n",
    "            else:\n",
    "                wk0Pow=wk0;\n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0Pow))); \n",
    "            \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            percentComplete=((iteration+1)*100)/maxIteration;\n",
    "            if( percentComplete%10==0 ):\n",
    "                print(\"Percent Completed\",percentComplete);\n",
    "            wk0=wk1;\n",
    "    else:\n",
    "        diffOffset=1e-20;\n",
    "        iteration=0;\n",
    "        oldRms=0;\n",
    "        voldRms=0;\n",
    "        while (True):            \n",
    "            if (wPow>1):\n",
    "                wk0Pow=np.power(wk0,wPow);            \n",
    "            else:\n",
    "                wk0Pow=wk0;\n",
    "            wk1=wk0-(alphaBym*((np.dot(phiTphi,wk0)-phiTy)+(lam*wk0Pow)));  \n",
    "            ystar=pridict(phi,wk1);\n",
    "            rms=getRMS(y,ystar);    \n",
    "            xaxis.append(iteration);\n",
    "            yaxis.append(rms);\n",
    "            diff=abs(oldRms-rms);\n",
    "            \n",
    "            vystar=pridict(validateDatasetPhi,wk1);\n",
    "            vrms=getRMS(validateDatasetY,vystar);\n",
    "            vdiff=voldRms-vrms;\n",
    "            \n",
    "            if(iteration>0 and  diff<=diffOffset):\n",
    "                break;\n",
    "            if(False and iteration%100==0 ):\n",
    "                print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff,\" vrms:\",vrms,\" vdiff:\", vdiff);            \n",
    "            wk0=wk1;\n",
    "            oldRms=rms;\n",
    "            voldRms=vrms;\n",
    "            iteration+=1;\n",
    "        print(\"# iteration: \",iteration,\" rms:\",rms,\"diff:\",diff,\" vrms:\",vrms,\" vdiff:\", vdiff);    \n",
    "\n",
    "    print(\"Final Trained RMS:\",rms ,\". Iteration needed \", iteration);       \n",
    "    #-------------------------------------------------------------\n",
    "    if(logReading):\n",
    "        writeReadingInFile(\"pnom.csv\",alpha,lam,iteration,rms,p);\n",
    "    plotGraph(xaxis,yaxis);\n",
    "    return wk1; \n",
    "\n",
    "#wStart=gardientDescentWithRidge(trainDatasetPhi,trainDatasetY);\n",
    "#wStart=gardientDescentWithPnom(trainDatasetPhi,trainDatasetY,4);\n",
    "#mainRidgeClosedFormSol();\n",
    "a=np.array([[1,2,3],[4,5,6]])\n",
    "b=np.array([[7,8,9],[10,11,12]])\n",
    "print(a);\n",
    "print(b);\n",
    "c=np.concatenate((a,b,a),axis=1);\n",
    "print(c);\n",
    "a=np.delete(a,0,1);\n",
    "print(a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Trained Dataset from file...\n",
      "Normalizing Phi...\n",
      "Normalization done.\n",
      "Normalizing Phi...\n",
      "Normalization done.\n",
      "Fetching of data Completed.\n",
      "Train Size:300\n",
      "Validate Size:120\n",
      "[ 15.90460106  -3.21834694  -1.38879586  -0.15884599  -7.55077175\n",
      "  -3.22111747   1.31157706   0.44741813  -3.44410773   5.20824187\n",
      "  -2.77230513  -1.51333764  -0.38952441  -5.73490039   0.22382741\n",
      "   0.49332809   0.70692655   2.51146936   0.02156689   0.72345934\n",
      "   0.29166302   0.62615066  -0.9872126    0.26154773   0.6830483\n",
      "  -0.28830539   1.25274581]\n",
      "Closed FormSol With Ridge RMS: 4.453313267200019\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mainClosedFormSol(dataset):\n",
    "    \n",
    "    tdsPhi=dataset[0];\n",
    "    tdsY=dataset[1];\n",
    "    vdsPhi=dataset[2];\n",
    "    vdsY=dataset[3];\n",
    "    ttds=dataset[4];\n",
    "    #--------------------[Closed Form Sol without Regularlization]--------------------------------\n",
    "    #Find w*\n",
    "    wStar=trainUsingClosedFormEquation(tdsPhi,tdsY);\n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(vdsPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(vdsY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(ttds,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Closed Form Solution RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    pass;\n",
    "\n",
    "\n",
    "def mainRidgeClosedFormSol(dataset):\n",
    "    #-------------------------------------\n",
    "    # Best value: m=300 validate=120\n",
    "    #-------------------------------------    \n",
    "    tdsPhi=dataset[0];\n",
    "    tdsY=dataset[1];\n",
    "    vdsPhi=dataset[2];\n",
    "    vdsY=dataset[3];\n",
    "    ttds=dataset[4];\n",
    "    #--------------------[Closed Form Sol without Regularlization]--------------------------------\n",
    "    #Find w*\n",
    "    wStar=trainUsingClosedFormRidgeEq(tdsPhi,tdsY);\n",
    "    print(wStar);\n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(vdsPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(vdsY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(ttds,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Closed FormSol With Ridge RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    pass;\n",
    "\n",
    "def mainGradientDesent(dataset):\n",
    "    tdsPhi=dataset[0];\n",
    "    tdsY=dataset[1];\n",
    "    vdsPhi=dataset[2];\n",
    "    vdsY=dataset[3];\n",
    "    ttds=dataset[4];\n",
    "    #--------------------[Gradient decent without Regularlization]--------------------------------\n",
    "    wStar=gardientDescentWithRidge(tdsPhi,tdsY);\n",
    "    #wStar=gardientDescentWithPnom(trainDatasetPhi,trainDatasetY,(4/3));\n",
    "    #Predict y* for Validate Data\n",
    "    ystar=pridict(vdsPhi,wStar);\n",
    "    #checking for RMS for Validate Data\n",
    "    rms=getRMS(vdsY,ystar);\n",
    "    #Predict y* for TestData\n",
    "    ystar=pridict(ttds,wStar);\n",
    "    writeTestData(ystar);\n",
    "    print(\"Gradient Desent ||Norm||=2 RMS:\",rms);\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "#split train data into Train and Validate\n",
    "def spitTrainDataset(phi,y):\n",
    "    m=len(phi);        \n",
    "    tdsSize=int(m*trainDSSizePercentage);\n",
    "    l=300;\n",
    "    trainDatasetPhi=phi[0:l];\n",
    "    trainDatasetY=y[0:l];\n",
    "    validateDatasetPhi=phi[tdsSize:m];\n",
    "    validateDatasetY=y[tdsSize:m];    \n",
    "   \n",
    "    return [trainDatasetPhi,trainDatasetY,validateDatasetPhi,validateDatasetY];    \n",
    "    pass\n",
    "\n",
    "def createNewFeatureMatrix(phi,maxDeg=4):    \n",
    "    newPhi=np.array(phi);\n",
    "    p=np.array(phi);        \n",
    "    if(addW0Col):#deleting first W0Col coffecient is 1\n",
    "        p=np.delete(p,0,1);    \n",
    "    i=2;\n",
    "    while(i<=maxDeg):\n",
    "        pPowI=np.power(p,i);        \n",
    "        newPhi=np.concatenate((newPhi,pPowI),axis=1);\n",
    "        i+=1;\n",
    "    return newPhi;\n",
    "    pass;\n",
    "\n",
    "#--settings--\n",
    "np.set_printoptions(suppress=True)\n",
    "#---init---\n",
    "dir=\"\"\n",
    "trainFile=dir+\"train.csv\";\n",
    "testFile=dir+\"test.csv\";\n",
    "trainDSSizePercentage=0.7; # x*100 percentage. 1-x data set will be used for validating\n",
    "addW0Col=True;\n",
    "#---------------------------------------------\n",
    "print(\"Fetching Trained Dataset from file...\");\n",
    "dataset=readTrainData(trainFile);\n",
    "testDS=readTestData(testFile);\n",
    "phiSet=dataset[0];\n",
    "ySet=dataset[1];\n",
    "phiSet_norm=normalizePhi(phiSet);\n",
    "testDS_norm=normalizePhi(testDS);\n",
    "tds=spitTrainDataset(phiSet,ySet);\n",
    "tds_norm=spitTrainDataset(phiSet_norm,ySet);\n",
    "\n",
    "print(\"Fetching of data Completed.\");\n",
    "\n",
    "#train set\n",
    "trainDatasetPhi=tds[0];\n",
    "trainDatasetY=tds[1];\n",
    "validateDatasetPhi=tds[2];\n",
    "validateDatasetY=tds[3];\n",
    "\n",
    "trainDatasetPhi_norm=tds_norm[0];\n",
    "trainDatasetY_norm=tds_norm[1];\n",
    "validateDatasetPhi_norm=tds_norm[2];\n",
    "validateDatasetY_norm=tds_norm[3];\n",
    "\n",
    "deg=2;\n",
    "trainDatasetPhi_norm=createNewFeatureMatrix(trainDatasetPhi_norm,deg);\n",
    "validateDatasetPhi_norm=createNewFeatureMatrix(validateDatasetPhi_norm,deg);\n",
    "testDS_norm=createNewFeatureMatrix(testDS_norm,deg);\n",
    "\n",
    "print(\"Train Size:\"+str(len(trainDatasetPhi)));\n",
    "print(\"Validate Size:\"+str(len(validateDatasetPhi)));\n",
    "\n",
    "ds=[trainDatasetPhi,trainDatasetY,validateDatasetPhi,validateDatasetY,testDS];\n",
    "ds_norm=[trainDatasetPhi_norm,trainDatasetY,validateDatasetPhi_norm,validateDatasetY,testDS_norm];\n",
    "#mainClosedFormSol(ds);\n",
    "#mainRidgeClosedFormSol(ds_norm);\n",
    "mainGradientDesent(ds_norm);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
